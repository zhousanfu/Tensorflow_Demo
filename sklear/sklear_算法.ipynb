{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/Data/text_classification-master.zip text_classification.zip\n",
    "!unzip text_classification.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "import jieba\n",
    "import time\n",
    "import warnings\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def read_text(path, text_list):\n",
    "    '''\n",
    "    path: 必选参数，文件夹路径\n",
    "    text_list: 必选参数，文件夹 path 下的所有 .txt 文件名列表\n",
    "    return: 返回值\n",
    "        features 文本(特征)数据，以列表形式返回; \n",
    "        labels 分类标签，以列表形式返回\n",
    "    '''\n",
    "    \n",
    "    features, labels = [], [] \n",
    "    for text in text_list:\n",
    "        if text.split('.')[-1] == 'txt':\n",
    "            try:\n",
    "                with open(path + text, encoding='gbk') as fp:\n",
    "                    features.append(fp.read())          # 特征 \n",
    "                    labels.append(path.split('/')[-2])  # 标签\n",
    "            except Exception as erro:\n",
    "                print('\\n>>>发现错误, 正在输出错误信息:', erro)\n",
    "                \n",
    "    return features, labels\n",
    "                    \n",
    "def merge_text(train_or_test, label_name):\n",
    "    '''\n",
    "    train_or_test: 必选参数，train 训练数据集 or test 测试数据集\n",
    "    label_name: 必选参数，分类标签的名字\n",
    "    return: 返回值\n",
    "        merge_features 合并好的所有特征数据，以列表形式返回;\n",
    "        merge_labels   合并好的所有分类标签数据，以列表形式返回\n",
    "    '''\n",
    "    \n",
    "    # print('\\n>>>文本读取和合并程序已经启动, 请稍候...')\n",
    "    \n",
    "    merge_features, merge_labels = [], []  # 函数全局变量\n",
    "    for name in label_name:\n",
    "        path = '/content/text_classification-master/text classification/'+ train_or_test +'/'+ name +'/'\n",
    "        text_list = os.listdir(path)\n",
    "        features, labels = read_text(path=path, text_list=text_list)  # 调用函数\n",
    "        merge_features += features  # 特征\n",
    "        merge_labels   += labels    # 标签\n",
    "        \n",
    "    # 可以自定义添加一些想要知道的信息\n",
    "    # print('\\n>>>你正在处理的数据类型是...\\n', train_or_test)\n",
    "    # print('\\n>>>[', train_or_test ,']数据具体情况如下...')\n",
    "    # print('样本数量\\t', len(merge_features), '\\t类别名称\\t', set(merge_labels))   \n",
    "    # print('\\n>>>文本读取和合并工作已经处理完毕...\\n')\n",
    "    \n",
    "    return merge_features, merge_labels\n",
    "\n",
    "train_or_test = 'train'\n",
    "label_name = ['女性', '体育', '校园', '文学']\n",
    "X_train, y_train = merge_text(train_or_test, label_name)\n",
    "train_or_test = 'test'\n",
    "label_name = ['女性', '体育', '校园', '文学']\n",
    "X_test, y_test = merge_text(train_or_test, label_name)\n",
    "X_test[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "stoplist = [word.strip() for word in open('/content/text_classification-master/text classification/stop/stopword.txt', encoding='utf-8').readlines()]\n",
    "stoplist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 编码器处理文本标签\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train_le = le.fit_transform(y_train)\n",
    "y_test_le  = le.fit_transform(y_test)\n",
    "\n",
    "y_train_le, y_test_le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 文本数据转换成数据值数据矩阵\n",
    "count = CountVectorizer(stop_words=stoplist) # 这里要先 count.fit() 训练所有训练和测试集，保证特征数一致，这样在算法建模时才不会报错\n",
    "\n",
    "jieba.enable_parallel(64) #并行分词开启\n",
    "X_train_word = [jieba.cut(words) for words in X_train]\n",
    "X_train_cut = [' '.join(word) for word in X_train_word]\n",
    "X_test_word = [jieba.cut(words) for words in X_test]\n",
    "X_test_cut  = [' '.join(word) for word in X_test_word]\n",
    "\n",
    "count.fit(list(X_train_cut) + list(X_test_cut))\n",
    "X_train_count = count.transform(X_train_cut)\n",
    "X_test_count  = count.transform(X_test_cut)\n",
    "\n",
    "X_train_count = X_train_count.toarray()\n",
    "X_test_count  = X_test_count.toarray()\n",
    "\n",
    "print(X_train_count.shape, X_test_count.shape)\n",
    "X_train_count, X_test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 用于存储所有算法的名字，准确率和所消耗的时间\n",
    "estimator_list, score_list, time_list = [], [], []\n",
    "\n",
    "def get_text_classification(estimator, X, y, X_test, y_test):\n",
    "    '''\n",
    "    estimator: 分类器，必选参数\n",
    "            X: 特征训练数据，必选参数\n",
    "            y: 标签训练数据，必选参数\n",
    "       X_test: 特征测试数据，必选参数\n",
    "        y_tes: 标签测试数据，必选参数\n",
    "       return: 返回值\n",
    "           y_pred_model: 预测值\n",
    "             classifier: 分类器名字\n",
    "                  score: 准确率\n",
    "                      t: 消耗的时间\n",
    "                  matrix: 混淆矩阵\n",
    "                  report: 分类评价函数\n",
    "                       \n",
    "    '''\n",
    "    start = time.time()\n",
    "    \n",
    "    # print('\\n>>>算法正在启动，请稍候...')\n",
    "    model = estimator\n",
    "    \n",
    "    # print('\\n>>>算法正在进行训练，请稍候...')\n",
    "    model.fit(X, y)\n",
    "    print(model)\n",
    "    \n",
    "    # print('\\n>>>算法正在进行预测，请稍候...')\n",
    "    y_pred_model = model.predict(X_test)\n",
    "    # print(y_pred_model)\n",
    "    \n",
    "    # print('\\n>>>算法正在进行性能评估，请稍候...')\n",
    "    score = metrics.accuracy_score(y_test, y_pred_model)\n",
    "    matrix = metrics.confusion_matrix(y_test, y_pred_model)\n",
    "    report = metrics.classification_report(y_test, y_pred_model)\n",
    "\n",
    "    print('>>>准确率', score)\n",
    "    print('\\n>>>召回率', report)\n",
    "    print('\\n>>>混淆矩阵', matrix)\n",
    "    # print('>>>算法程序已经结束...')\n",
    "    \n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    print('\\n>>>算法消耗时间为：', t, '秒\\n')\n",
    "    classifier = str(model).split('(')[0]\n",
    "    \n",
    "    return y_pred_model, classifier, score, round(t, 2), matrix, report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def multiclass_logloss(actual, predicted, eps=1e-15):\n",
    "    \"\"\"对数损失度量（Logarithmic Loss  Metric）的多分类版本。\n",
    "    :param actual: 包含actual target classes的数组\n",
    "    :param predicted: 分类预测结果矩阵, 每个类别都有一个概率\n",
    "    \"\"\"\n",
    "    # Convert 'actual' to a binary array if it's not already:\n",
    "    if len(actual.shape) == 1:\n",
    "        actual2 = np.zeros((actual.shape[0], predicted.shape[1]))\n",
    "        for i, val in enumerate(actual):\n",
    "            actual2[i, val] = 1\n",
    "        actual = actual2\n",
    "\n",
    "    clip = np.clip(predicted, eps, 1 - eps)\n",
    "    rows = actual.shape[0]\n",
    "    vsota = np.sum(actual * np.log(clip))\n",
    "    return -1.0 / rows * vsota\n",
    "\n",
    "def number_normalizer(tokens):\n",
    "    \"\"\" 将所有数字标记映射为一个占位符（Placeholder）。\n",
    "    对于许多实际应用场景来说，以数字开头的tokens不是很有用，\n",
    "    但这样tokens的存在也有一定相关性。 通过将所有数字都表示成同一个符号，可以达到降维的目的。\n",
    "    \"\"\"\n",
    "    return (\"#NUMBER\" if token[0].isdigit() else token for token in tokens)\n",
    "\n",
    "class NumberNormalizingVectorizer(TfidfVectorizer):\n",
    "    def build_tokenizer(self):\n",
    "        tokenize = super(NumberNormalizingVectorizer, self).build_tokenizer()\n",
    "        return lambda doc: list(number_normalizer(tokenize(doc)))\n",
    "\n",
    "\n",
    "tfv = NumberNormalizingVectorizer(min_df=3,  \n",
    "                                  max_df=0.5,\n",
    "                                  max_features=None,                 \n",
    "                                  ngram_range=(1, 2), \n",
    "                                  use_idf=True,\n",
    "                                  smooth_idf=True,\n",
    "                                  stop_words = stoplist)\n",
    "\n",
    "# 使用TF-IDF来fit训练集和测试集（半监督学习）\n",
    "tfv.fit(list(X_train_cut) + list(X_test_cut))\n",
    "xtrain_tfv =  tfv.transform(X_train_cut) \n",
    "xvalid_tfv = tfv.transform(X_test_cut)\n",
    "\n",
    "#利用提取的TFIDF特征来fit一个简单的Logistic Regression \n",
    "clf = LogisticRegression(C=1.0,solver='lbfgs',multi_class='multinomial')\n",
    "clf.fit(xtrain_tfv, X_train_cut)\n",
    "predictions = clf.predict_proba(xvalid_tfv)\n",
    "\n",
    "print (\"logloss: %0.3f \" % multiclass_logloss(X_train_cut, predictions))\n",
    "#print(classification_report(predictions, yvalid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k 近邻算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "knc = KNeighborsClassifier()\n",
    "\n",
    "result = get_text_classification(knc, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "result = get_text_classification(dtc, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多层感知器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mlpc = MLPClassifier()\n",
    "\n",
    "result = get_text_classification(mlpc, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 伯努力贝叶斯算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()\n",
    "\n",
    "result = get_text_classification(bnb, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 高斯贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "result = get_text_classification(gnb, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多项式朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "\n",
    "result = get_text_classification(mnb, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逻辑回归算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "lgr = LogisticRegression()\n",
    "\n",
    "result = get_text_classification(lgr, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 支持向量机算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC()\n",
    "\n",
    "result = get_text_classification(svc, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机森林算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "result = get_text_classification(rfc, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自增强算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "\n",
    "result = get_text_classification(abc, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lightgbm算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "gbm = lightgbm.LGBMClassifier()\n",
    "\n",
    "result = get_text_classification(gbm, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgboost算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "xgb = xgboost.XGBClassifier()#(max_depth=7, n_estimators=200, colsample_bytree=0.8, subsample=0.8, nthread=10, learning_rate=0.1)\n",
    "\n",
    "result = get_text_classification(xgb, X_train_count, y_train_le, X_test_count, y_test_le)\n",
    "estimator_list.append(result[1]), score_list.append(result[2]), time_list.append(result[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 多分类前馈神经网络\n",
    "1 算法流程：  \n",
    "创建神经网络——添加神经层——编译神经网络——训练神经网络——预测——性能评估——保存模型  \n",
    "\n",
    "2 添加神经层  \n",
    "至少要有两层神经层，第一层必须是输入神经层，最后一层必须是输出层；  \n",
    "输入神经层主要设置输入的维度，而最后一层主要是设置激活函数的类型来指明是分类还是回归问题  \n",
    "\n",
    "3 编译神经网络  \n",
    "分类问题的 metrics，一般以 accuracy 准确率来衡量  \n",
    "回归问题的 metrics, 一般以 mae 平均绝对误差来衡量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "# np.random.seed(0)     # 设置随机数种子\n",
    "feature_num = X_train_count.shape[1]     # 设置所希望的特征数量\n",
    "\n",
    "# 独热编码目标向量来创建目标矩阵\n",
    "y_train_cate = to_categorical(y_train_le)\n",
    "y_test_cate = to_categorical(y_test_le)\n",
    "print(y_train_cate)\n",
    "\n",
    "# 1 创建神经网络\n",
    "network = models.Sequential() \n",
    "\n",
    "# 2 添加神经连接层 第一层必须有并且一定是 [输入层], 必选\n",
    "network.add(layers.Dense(     # 添加带有 relu 激活函数的全连接层\n",
    "                         units=128, \n",
    "                         activation='relu', \n",
    "                         input_shape=(feature_num, )\n",
    "                         ))\n",
    "# 介于第一层和最后一层之间的称为 [隐藏层]，可选\n",
    "network.add(layers.Dense(     # 添加带有 relu 激活函数的全连接层\n",
    "                         units=128, \n",
    "                         activation='relu'\n",
    "                         ))\n",
    "network.add(layers.Dropout(0.8))\n",
    "# 最后一层必须有并且一定是 [输出层], 必选                         \n",
    "network.add(layers.Dense(     # 添加带有 softmax 激活函数的全连接层\n",
    "                         units=4,\n",
    "                         activation='sigmoid'\n",
    "                         ))\n",
    "\n",
    "# 3 编译神经网络\n",
    "network.compile(loss='categorical_crossentropy',  # 分类交叉熵损失函数    \n",
    "                optimizer='rmsprop',  \n",
    "                metrics=['accuracy']              # 准确率度量\n",
    "                )\n",
    "\n",
    "\n",
    "# 4 开始训练神经网络\n",
    "history = network.fit(X_train_count,     # 训练集特征\n",
    "            y_train_cate,        # 训练集标签\n",
    "            epochs=20,          # 迭代次数\n",
    "            batch_size=300,    # 每个批量的观测数  可做优化\n",
    "            validation_data=(X_test_count, y_test_cate)  # 验证测试集数据\n",
    "            )\n",
    "network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5 模型预测\n",
    "y_pred_keras = network.predict(X_test_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6 性能评估\n",
    "print('>>>多分类前馈神经网络性能评估如下...\\n')\n",
    "score = network.evaluate(X_test_count,\n",
    "                        y_test_cate,\n",
    "                        batch_size=32)\n",
    "print('\\n>>>评分\\n', score)\n",
    "print()\n",
    "end = time.time()\n",
    "\n",
    "estimator_list.append('前馈网络')\n",
    "score_list.append(score[1])\n",
    "time_list.append(round(end-start, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 损失函数情况\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_loss = history.history[\"loss\"]\n",
    "valid_loss = history.history[\"val_loss\"]\n",
    "epochs = [i for i in range(len(train_loss))]\n",
    "plt.plot(epochs, train_loss,linewidth=3.0)\n",
    "plt.plot(epochs, valid_loss,linewidth=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 准确率情况\n",
    "train_loss = history.history[\"accuracy\"]\n",
    "valid_loss = history.history[\"val_accuracy\"]\n",
    "epochs = [i for i in range(len(train_loss))]\n",
    "plt.plot(epochs, train_loss,linewidth=3.0)\n",
    "plt.plot(epochs, valid_loss,linewidth=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 保存\n",
    "print('\\n>>>你正在进行保存模型操作, 请稍候...\\n')\n",
    "\n",
    "network.save('/home/kesci/work/xiaozhi/my_network_model.h5')\n",
    "\n",
    "print('>>>保存工作已完成...\\n')\n",
    "\n",
    "\n",
    "# 加载和使用\n",
    "print('>>>你正在加载已经训练好的模型, 请稍候...\\n')\n",
    "\n",
    "my_load_model = models.load_model('/home/kesci/work/xiaozhi/my_network_model.h5')\n",
    "\n",
    "print('>>>你正在使用加载的现成模型进行预测, 请稍候...\\n')\n",
    "print('>>>预测部分结果如下...')\n",
    "\n",
    "my_load_model.predict(X_test_count)[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 设置所希望的特征数\n",
    "feature_num = X_train_count.shape[1] \n",
    "\n",
    "# 使用单热编码目标向量对标签进行处理\n",
    "y_train_cate = to_categorical(y_train_le)\n",
    "y_test_cate = to_categorical(y_test_le)\n",
    "\n",
    "print(y_train_cate)\n",
    "\n",
    "# 1 创建神经网络\n",
    "lstm_network = models.Sequential()\n",
    "\n",
    "# 2 添加神经层\n",
    "lstm_network.add(layers.Embedding(input_dim=feature_num, output_dim=4))     # 添加嵌入层\n",
    "lstm_network.add(layers.LSTM(units=128))                                    # 添加 128 个单元的 LSTM 神经层\n",
    "lstm_network.add(layers.Dense(units=4,activation='sigmoid'))                # 添加 sigmoid 分类激活函数的全连接层\n",
    "\n",
    "# 3 编译神经网络\n",
    "lstm_network.compile(loss='binary_crossentropy',\n",
    "                     optimizer='Adam',\n",
    "                     metrics=['accuracy']\n",
    "                     )\n",
    "\n",
    "# 4 开始训练模型\n",
    "lstm_network.fit(X_train_count,\n",
    "                 y_train_cate,\n",
    "                 epochs=5,\n",
    "                 batch_size=128,\n",
    "                 validation_data=(X_test_count, y_test_cate)\n",
    "                 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 算法之间性能比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['分类器'] = estimator_list\n",
    "df['准确率'] = score_list\n",
    "df['消耗时间/s'] = time_list\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
