{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqtSXvJChp4Y72YrLwycqz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhousanfu/machine-learning-demo/blob/master/%E8%A5%BF%E5%82%A8%E5%A4%A7%E5%AD%A6%E8%BD%B4%E6%89%BF%E6%95%85%E9%9A%9C%E6%95%B0%E6%8D%AE%E5%88%86%E7%B1%BB_MK_MMD%E5%BA%A6%E9%87%8F%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4U00V5BJqxJg",
        "outputId": "6a39f761-148e-48c7-fbbe-ff76f79e063f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "[[7 6 5]\n",
            " [4 3 2]\n",
            " [1 1 8]\n",
            " [0 2 5]]\n",
            "6.0\n",
            "0.5822068619587334\n",
            "2436.5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn import metrics\n",
        " \n",
        " \n",
        "def mmd_linear(X, Y):\n",
        "    \"\"\"MMD using linear kernel (i.e., k(x,y) = <x,y>)\n",
        "    Note that this is not the original linear MMD, only the reformulated and faster version.\n",
        "    The original version is:\n",
        "        def mmd_linear(X, Y):\n",
        "            XX = np.dot(X, X.T)\n",
        "            YY = np.dot(Y, Y.T)\n",
        "            XY = np.dot(X, Y.T)\n",
        "            return XX.mean() + YY.mean() - 2 * XY.mean()\n",
        "    Arguments:\n",
        "        X {[n_sample1, dim]} -- [X matrix]\n",
        "        Y {[n_sample2, dim]} -- [Y matrix]\n",
        "    Returns:\n",
        "        [scalar] -- [MMD value]\n",
        "    \"\"\"\n",
        "    delta = X.mean(0) - Y.mean(0)\n",
        "    return delta.dot(delta.T)\n",
        " \n",
        " \n",
        "def mmd_rbf(X, Y, gamma=1.0):\n",
        "    \"\"\"MMD using rbf (gaussian) kernel (i.e., k(x,y) = exp(-gamma * ||x-y||^2 / 2))\n",
        "    Arguments:\n",
        "        X {[n_sample1, dim]} -- [X matrix]\n",
        "        Y {[n_sample2, dim]} -- [Y matrix]\n",
        "    Keyword Arguments:\n",
        "        gamma {float} -- [kernel parameter] (default: {1.0})\n",
        "    Returns:\n",
        "        [scalar] -- [MMD value]\n",
        "    \"\"\"\n",
        "    XX = metrics.pairwise.rbf_kernel(X, X, gamma)\n",
        "    YY = metrics.pairwise.rbf_kernel(Y, Y, gamma)\n",
        "    XY = metrics.pairwise.rbf_kernel(X, Y, gamma)\n",
        "    return XX.mean() + YY.mean() - 2 * XY.mean()\n",
        " \n",
        " \n",
        "def mmd_poly(X, Y, degree=2, gamma=1, coef0=0):\n",
        "    \"\"\"MMD using polynomial kernel (i.e., k(x,y) = (gamma <X, Y> + coef0)^degree)\n",
        "    Arguments:\n",
        "        X {[n_sample1, dim]} -- [X matrix]\n",
        "        Y {[n_sample2, dim]} -- [Y matrix]\n",
        "    Keyword Arguments:\n",
        "        degree {int} -- [degree] (default: {2})\n",
        "        gamma {int} -- [gamma] (default: {1})\n",
        "        coef0 {int} -- [constant item] (default: {0})\n",
        "    Returns:\n",
        "        [scalar] -- [MMD value]\n",
        "    \"\"\"\n",
        "    XX = metrics.pairwise.polynomial_kernel(X, X, degree, gamma, coef0)\n",
        "    YY = metrics.pairwise.polynomial_kernel(Y, Y, degree, gamma, coef0)\n",
        "    XY = metrics.pairwise.polynomial_kernel(X, Y, degree, gamma, coef0)\n",
        "    return XX.mean() + YY.mean() - 2 * XY.mean()\n",
        " \n",
        " \n",
        "if __name__ == '__main__':\n",
        "    a = np.arange(1, 10).reshape(3, 3)\n",
        "    b = [[7, 6, 5], [4, 3, 2], [1, 1, 8], [0, 2, 5]]\n",
        "    b = np.array(b)\n",
        "    print(a)\n",
        "    print(b)\n",
        "    print(mmd_linear(a, b))  # 6.0\n",
        "    print(mmd_rbf(a, b))  # 0.5822\n",
        "    print(mmd_poly(a, b))  # 2436.5\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
        "    '''\n",
        "    多核或单核高斯核矩阵函数，根据输入样本集x和y，计算返回对应的高斯核矩阵\n",
        "    Params:\n",
        "     source: (b1,n)的X分布样本数组\n",
        "     target:（b2，n)的Y分布样本数组\n",
        "     kernel_mul: 多核MMD，以bandwidth为中心，两边扩展的基数，比如bandwidth/kernel_mul, bandwidth, bandwidth*kernel_mul\n",
        "     kernel_num: 取不同高斯核的数量\n",
        "     fix_sigma: 是否固定，如果固定，则为单核MMD\n",
        "    Return:\n",
        "      sum(kernel_val): 多个核矩阵之和\n",
        "    '''\n",
        "    # 堆叠两组样本，上面是X分布样本，下面是Y分布样本，得到（b1+b2,n）组总样本\n",
        "    n_samples = int(source.shape[0]) + int(target.shape[0])\n",
        "    total = np.concatenate((source, target), axis=0)\n",
        "    # 对总样本变换格式为（1,b1+b2,n）,然后将后两维度数据复制到新拓展的维度上（b1+b2，b1+b2,n），相当于按行复制\n",
        "    total0 = np.expand_dims(total, axis=0)\n",
        "    total0 = np.broadcast_to(total0, [int(total.shape[0]), int(total.shape[0]), int(total.shape[1])])\n",
        "    # 对总样本变换格式为（b1+b2,1,n）,然后将后两维度数据复制到新拓展的维度上（b1+b2，b1+b2,n），相当于按复制\n",
        "    total1 = np.expand_dims(total, axis=1)\n",
        "    total1 = np.broadcast_to(total1, [int(total.shape[0]), int(total.shape[0]), int(total.shape[1])])\n",
        "    # total1 - total2 得到的矩阵中坐标（i,j, :）代表total中第i行数据和第j行数据之间的差\n",
        "    # sum函数，对第三维进行求和，即平方后再求和，获得高斯核指数部分的分子，是L2范数的平方\n",
        "    L2_distance_square = np.cumsum(np.square(total0 - total1), axis=2)\n",
        "    # 调整高斯核函数的sigma值\n",
        "    if fix_sigma:\n",
        "        bandwidth = fix_sigma\n",
        "    else:\n",
        "        bandwidth = np.sum(L2_distance_square) / (n_samples ** 2 - n_samples)\n",
        "    # 多核MMD\n",
        "    # 以fix_sigma为中值，以kernel_mul为倍数取kernel_num个bandwidth值（比如fix_sigma为1时，得到[0.25,0.5,1,2,4]\n",
        "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
        "    bandwidth_list = [bandwidth * (kernel_mul ** i) for i in range(kernel_num)]\n",
        "    # print(bandwidth_list)\n",
        "    # 高斯核函数的数学表达式\n",
        "    kernel_val = [np.exp(-L2_distance_square / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
        "    # 得到最终的核矩阵\n",
        "    return sum(kernel_val)  # 多核合并\n",
        " \n",
        " \n",
        "def MK_MMD(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
        "    '''\n",
        "    计算源域数据和目标域数据的MMD距离\n",
        "    Params:\n",
        "     source: (b1,n)的X分布样本数组\n",
        "     target:（b2，n)的Y分布样本数组\n",
        "     kernel_mul: 多核MMD，以bandwidth为中心，两边扩展的基数，比如bandwidth/kernel_mul, bandwidth, bandwidth*kernel_mul\n",
        "     kernel_num: 取不同高斯核的数量\n",
        "     fix_sigma: 是否固定，如果固定，则为单核MMD\n",
        " Return:\n",
        "     loss: MK-MMD loss\n",
        "    '''\n",
        "    batch_size = int(source.shape[0])  # 一般默认为源域和目标域的batchsize相同\n",
        "    kernels = guassian_kernel(source, target,kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
        "    # 将核矩阵分成4部分\n",
        "    loss = 0\n",
        "    for i in range(batch_size):\n",
        "        s1, s2 = i, (i + 1) % batch_size\n",
        "        t1, t2 = s1 + batch_size, s2 + batch_size\n",
        "        loss += kernels[s1, s2] + kernels[t1, t2]\n",
        "        loss -= kernels[s1, t2] + kernels[s2, t1]\n",
        "    # 这里计算出的n_loss是每个维度上的MK-MMD距离，一般还会做均值化处理\n",
        "    n_loss = loss / float(batch_size)\n",
        "    return np.mean(n_loss)\n"
      ],
      "metadata": {
        "id": "28rv5nhsq0TG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}