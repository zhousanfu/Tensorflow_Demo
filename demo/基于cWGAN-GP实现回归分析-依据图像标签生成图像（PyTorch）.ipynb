{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cWGAN-GP**（条件生成对抗网络-梯度惩罚）模型。该模型可以根据输入的标签信息生成对应的灰度图像。以下是使用PyTorch实现cWGAN-GP模型的代码示例"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个代码示例中，我们使用了cWGAN-GP模型来进行灰度图像的生成。需要注意的是，我们将标签信息和真实图像进行拼接作为判别器的输入，同时将标签信息作为生成器的输入，从而实现对灰度图像的生成。\n",
    "\n",
    "如果任务是对彩色图像进行回归分析，可以将上述代码中的灰度图像替换为彩色图像，并相应地调整模型参数和超参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Sanfor Chow\n",
    "Date: 2023-02-27 11:23:06\n",
    "LastEditors: Sanfor Chow\n",
    "LastEditTime: 2023-02-27 17:38:52\n",
    "FilePath: /machine-learning-demo/实例/基于cWGAN-GP实现回归分析-依据图像标签生成图像（PyTorch）.ipynb\n",
    "'''\n",
    "\n",
    "\n",
    "# 导入相关库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# 设置随机种子以便复现\n",
    "torch.manual_seed(2021)\n",
    "\n",
    "# 定义超参数\n",
    "batch_size = 64\n",
    "lr = 0.0002\n",
    "n_epoch = 10\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 1\n",
    "\n",
    "# 加载数据集\n",
    "dataset = dset.ImageFolder(root=\"data\",\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Grayscale(),\n",
    "                                transforms.Resize(64),\n",
    "                                transforms.CenterCrop(64),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))\n",
    "                            ]))\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 定义生成器模型\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "# 定义判别器模型\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1)\n",
    "\n",
    "# 定义cWGAN-GP模型\n",
    "class cWGAN_GP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(cWGAN_GP, self).__init__()\n",
    "        self.generator = Generator()\n",
    "        self.discriminator = Discriminator()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.generator(input)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_G = optim.Adam(netG.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(netD.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(n_epoch):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        # 更新判别器\n",
    "        netD.zero_grad()\n",
    "        real_cpu, _ = data\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.randn(batch_size, nz, 1, 1)\n",
    "        input = torch.cat((label, real_cpu), 1)\n",
    "        output = netD(input)\n",
    "        label.fill_(1)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        fake = netG(label)\n",
    "        label.fill_(0)\n",
    "        input = torch.cat((label, fake.detach()), 1)\n",
    "        output = netD(input)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # 更新生成器\n",
    "        netG.zero_grad()\n",
    "        label.fill_(1)\n",
    "        input = torch.cat((label, fake), 1)\n",
    "        output = netD(input)\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # 输出损失值和中间结果\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, n_epoch, i, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # 保存中间结果\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real_cpu, './results/real_samples.png',\n",
    "                              normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(), './results/fake_samples_epoch_%03d.png' % epoch,\n",
    "                              normalize=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
