{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd36b9d4-bb12-493b-85ba-aef98c190d41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc8d6482-2f9d-4d66-a903-0669e4018858",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "import re\n",
    "import jieba\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence, Text8Corpus\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad1b138d-2020-439e-80c5-13047fc42769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aid/Github/synonym_detection\n"
     ]
    }
   ],
   "source": [
    "rootPath = '/home/aid/Github/synonym_detection'#os.path.dirname(os.getcwd())\n",
    "dataPath = rootPath + '/data'\n",
    "print(rootPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d9a30-dc76-4412-bbbb-6fc0f476f08a",
   "metadata": {},
   "source": [
    "### 数据获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55ce8017-b1af-49e1-aaa8-601a75c1e7d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7164844\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import re\n",
    "import json\n",
    "\n",
    "def get_mysql_data():\n",
    "    '''description: 获取mysql数据\n",
    "    '''\n",
    "    connection = pymysql.connect(host='192.168.100.50', port=3306, user='root', password='Aid@pro888888', db='nlp_tagging', charset='utf8mb4')\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(\"SELECT doc_content FROM `aid-tagging`.document\")\n",
    "    data = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "doc_data = get_mysql_data()\n",
    "with open(dataPath+'/dk_mainsuit_800w.txt', 'w') as f:\n",
    "    for doc in doc_data:\n",
    "        try:\n",
    "            doc_v = doc[0].replace('\\n', '').replace('\\r', '').replace(' ','').strip()\n",
    "            f.write(doc_v + '\\n')\n",
    "        except:\n",
    "            pass\n",
    "f.close()\n",
    "print(len(doc_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575e492-1aeb-4f9b-9f37-9ca802b97f55",
   "metadata": {},
   "source": [
    "### 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cea428be-8531-4c3f-ba34-683346c71437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(line):\n",
    "    line = str(line)\n",
    "    if line.strip()=='':\n",
    "        return ''\n",
    "    rule = re.compile(u\"\"\"[^a-zA-Z0-9\\u4E00-\\u9FA5]|[a-zA-Z0-9'!\"#$%&\\'()*+,-./:;<=>?@，。?★、…【】《》？“”‘'！[\\\\]^_`{|}~\\s]+|[\\001\\002\\003\\004\\005\\006\\007\\x08\\x09\\x0a\\x0b\\x0c\\x0d\\x0e\\x0f\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1a]+\"\"\")\n",
    "    line = rule.sub('',line)\n",
    "    return line\n",
    "\n",
    "def split_sentence(sentence):\n",
    "    '''description: 分句\n",
    "    '''    \n",
    "    re_sentencesp = re.compile('([﹒﹔﹖﹗．；。！？][\"’”」』]{0,2}|：(?=[\"‘“「『]{1,2}|$))')\n",
    "    s = sentence\n",
    "    slist = []\n",
    "    for i in re_sentencesp.split(s):\n",
    "        if re_sentencesp.match(i) and slist:\n",
    "            slist[-1] += i\n",
    "        elif i:\n",
    "            slist.append(i)\n",
    "    return slist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e6012bf-afde-41c5-99c8-9d97b3159f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7164844 患者 主诉 发热 天 咳嗽 天现 病史 天前 患儿 无 明显 诱因 出现 发热 热峰 为 伴有 寒战 无 抽搐 予 退热药 后 体温 可降 至 正常 偶有 咳嗽 为 刺激性 干咳 无 喘息 无 气促 及 呼吸困难 无 烦躁不安 无 皮疹 门诊 查 血常规 门诊 考虑 为 脓 毒血症 门诊 予美洛 西林 舒巴坦 静滴 天 抗感染 治疗 后 病情 未见 明显好转 今为 进一步 治疗 来 我院 就诊 门诊 以脓 毒血症 收入 院自 发病 以来 病人 精神状态 一般 体力 情况 一般 食欲 食量 一般 睡眠 情况 一般 既往 史 否认 肝炎 结核 传染病 史 否认 手术 外伤 史 否认 输血 史 按 当地 防疫 部门 要求 预防接种 传染病 史 否认 肝炎 结核 等 传染病 史 预防接种 史 乙肝 卡介苗 白百破 脊髓灰质炎 麻疹 乙脑 其他 部分 接种 手术 史因 左侧 腹股沟 斜 疝 右侧 鞘 状 突未闭 在 我院 普外科 住院治疗 予行 腹腔镜 左侧 腹股沟 斜 疝 修补术 右侧 鞘 状 突未闭 修补术 输血 史 既往 因 贫血 输血 治疗 次 过敏史 对 牛奶 牛肉 海鲜 及 西红柿 过敏 个人 史 出生 史 第胎 第产 孕期 周 分娩 因 羊水 过少行 剖宫产 出生 体重 克 出生 时 情况 无 窒息 产伤 史母 孕期 健康 体健 家族史 父亲 年龄 岁 健康状况 健康 母亲 年龄 岁 健康状况 健康 母曾 孕胎 流产 胎 人流 胎 死胎 其他 婚育 史 月经 史 婚姻 史 生育 史 月经 史 初潮 岁 天天 末次 月经\n"
     ]
    }
   ],
   "source": [
    "file_reader = codecs.open(dataPath+'/dk_mainsuit_800w.txt', 'r', 'utf-8',errors=\"ignore\")\n",
    "source_lines = file_reader.readlines()\n",
    "file_reader.close()\n",
    "\n",
    "stop_keyword = [line.strip() for line in codecs.open(dataPath+'/stopword_zh.txt','r','utf-8').readlines()]\n",
    "\n",
    "source_lines = [remove_punctuation(w) for w in source_lines]\n",
    "source_cut = [\" \".join(jieba.cut(w)) for w in source_lines if w not in stop_keyword]\n",
    "\n",
    "output = codecs.open(rootPath+'/word2vec/separated_file.txt', 'w', 'utf-8')\n",
    "for line in source_cut:\n",
    "    output.write(line)\n",
    "output.close()\n",
    "print(len(source_cut), source_cut[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4eaa99-5beb-4652-9272-dd28affb3835",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58a8a47c-319c-42a3-bb86-2b1919f32525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#source_cut:分好词的文本\n",
    "#outp1:训练好的模型\n",
    "#outp2:得到的词向量\n",
    "model = Word2Vec(LineSentence(rootPath+'/word2vec/separated_file.txt'), vector_size=200, window=5, min_count=5, workers=multiprocessing.cpu_count())\n",
    "model.save(rootPath+'/word2vec/separated.model')\n",
    "#不以C语言可以解析的形式存储词向量\n",
    "model.wv.save_word2vec_format(rootPath+'/word2vec/separated.vector', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24bb06e-9158-47b3-acbb-15866901eaa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 可视化图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65fc03f-3a59-4ecb-9d82-b809e01ca7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.vocab:\n",
    "        tokens.append(model[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(18, 18)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()\n",
    "    \n",
    "tsne_plot(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6073f7b1-2087-4f01-86be-853579c21dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wv_df = pd.DataFrame(model[model.wv.vocab], list(model.wv.vocab))\n",
    "keywords = [\"行情\", \"旅游\", \"手机\", \"股权\",\"基金\", \"招聘\", \"高考\", \"分析\",\"录取\", \\\n",
    "            \"学生\", \"员工\", '军事', '老板', '战争','国际', '服务',\"健康\",\"地区\",\\\n",
    "           \"俄罗斯\",\"台湾\",\"中国\",\"董事会\",\"风险\",\"部队\"]\n",
    "words = [word for word in keywords if word in list(model.wv.vocab)]\n",
    "\n",
    "X = model_wv_df.T[words].T\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "df = pd.DataFrame(result, columns=[\"Component 1\", \"Component 2\"])\n",
    "df[\"Word\"] = keywords\n",
    "df[\"Distance\"] = np.sqrt(df[\"Component 1\"]**2 + df[\"Component 2\"]**2)\n",
    "fig = px.scatter(df, x=\"Component 1\", y=\"Component 2\", text=\"Word\", color=\"Distance\", color_continuous_scale=\"agsunset\",size=\"Distance\")\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.layout.xaxis.autorange = True\n",
    "fig.data[0].marker.line.width = 1\n",
    "fig.data[0].marker.line.color = 'rgb(0, 0, 0)'\n",
    "fig.update_layout(height=800,  template=\"plotly_white\", paper_bgcolor=\"#f0f0f0\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e2263-43de-4dd4-ad73-968c88948a19",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e2812c-3508-4480-9c33-1d8a3eb1667c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('内未见', 0.6911172866821289),\n",
       " ('余未见', 0.566469669342041),\n",
       " ('区未见', 0.563393235206604),\n",
       " ('影未见', 0.5555785894393921),\n",
       " ('示未见', 0.5357312560081482),\n",
       " ('暂未见', 0.5343140363693237),\n",
       " ('无', 0.47653254866600037),\n",
       " ('腺未见', 0.43761494755744934),\n",
       " ('叶未见', 0.4373205006122589),\n",
       " ('下未见', 0.433382511138916),\n",
       " ('超未见', 0.431390643119812),\n",
       " ('处未见', 0.43025442957878113),\n",
       " ('胰未见', 0.41962721943855286),\n",
       " ('腹未见', 0.41961655020713806),\n",
       " ('骨未见', 0.4077603220939636),\n",
       " ('整未见', 0.40723374485969543),\n",
       " ('灶未见', 0.39857786893844604),\n",
       " ('扫未见', 0.3926079571247101),\n",
       " ('未见异常', 0.38501209020614624),\n",
       " ('现未见', 0.38494664430618286),\n",
       " ('率未见', 0.38264599442481995),\n",
       " ('项未见', 0.3762330710887909),\n",
       " ('可未见', 0.3759281039237976),\n",
       " ('见', 0.3735075891017914),\n",
       " ('肾未见', 0.3721506595611572),\n",
       " ('支未见', 0.37003573775291443),\n",
       " ('未示', 0.36812785267829895),\n",
       " ('片未见', 0.36710235476493835),\n",
       " ('余全', 0.36054834723472595),\n",
       " ('值未见', 0.3577535152435303),\n",
       " ('征象', 0.3547970950603485),\n",
       " ('影无', 0.3529451787471771),\n",
       " ('团未见', 0.351279079914093),\n",
       " ('端未见', 0.34286531805992126),\n",
       " ('脾未见', 0.3416326344013214),\n",
       " ('优胚', 0.3359661400318146),\n",
       " ('检未见', 0.3347908556461334),\n",
       " ('超无', 0.3316045105457306),\n",
       " ('窦未见', 0.3309146761894226),\n",
       " ('畅未见', 0.3278382122516632),\n",
       " ('结构', 0.3271794021129608),\n",
       " ('癌未见', 0.32699379324913025),\n",
       " ('肌未见', 0.32612499594688416),\n",
       " ('未', 0.32607442140579224),\n",
       " ('图未见', 0.32205307483673096),\n",
       " ('大弯处', 0.3196586072444916),\n",
       " ('示残肝', 0.3175491392612457),\n",
       " ('形态', 0.3153664171695709),\n",
       " ('束未见', 0.3132944405078888),\n",
       " ('器未见', 0.31172308325767517),\n",
       " ('影呈长', 0.30854740738868713),\n",
       " ('可见', 0.3075490891933441),\n",
       " ('平扫及', 0.3064499497413635),\n",
       " ('各辅', 0.306332528591156),\n",
       " ('淡未见', 0.3057593107223511),\n",
       " ('白无', 0.3054361343383789),\n",
       " ('管未见', 0.3046787977218628),\n",
       " ('大未见', 0.30337369441986084),\n",
       " ('期无', 0.30079227685928345),\n",
       " ('旁未见', 0.30061158537864685),\n",
       " ('物未见', 0.29988446831703186),\n",
       " ('背寒', 0.29920366406440735),\n",
       " ('冠未见', 0.29912373423576355),\n",
       " ('未及', 0.2987837493419647),\n",
       " ('清未见', 0.2981741726398468),\n",
       " ('位未见', 0.29748594760894775),\n",
       " ('拟闹', 0.29689309000968933),\n",
       " ('所示', 0.29266488552093506),\n",
       " ('肝脾及', 0.2900591492652893),\n",
       " ('更为', 0.28892776370048523),\n",
       " ('较淡', 0.28855565190315247),\n",
       " ('精囊', 0.28733330965042114),\n",
       " ('残部', 0.2865869998931885),\n",
       " ('元', 0.2858335077762604),\n",
       " ('见线样', 0.2855013906955719),\n",
       " ('各属', 0.28504320979118347),\n",
       " ('征腹软', 0.28499045968055725),\n",
       " ('样双侧', 0.28496575355529785),\n",
       " ('沿胃', 0.2842794954776764),\n",
       " ('示无', 0.28400900959968567),\n",
       " ('期未见', 0.28395089507102966),\n",
       " ('未见明', 0.2824099063873291),\n",
       " ('双肾', 0.2810402810573578),\n",
       " ('胸全', 0.28086161613464355),\n",
       " ('变未见', 0.27855896949768066),\n",
       " ('脾超', 0.2779349982738495),\n",
       " ('少未见', 0.2773854732513428),\n",
       " ('壁未见', 0.2768401503562927),\n",
       " ('正常', 0.2759799361228943),\n",
       " ('时未见', 0.27401936054229736),\n",
       " ('可测', 0.2738518714904785),\n",
       " ('脑未见', 0.27385103702545166),\n",
       " ('从下到上', 0.27306801080703735),\n",
       " ('上均', 0.2729499042034149),\n",
       " ('段始', 0.27071061730384827),\n",
       " ('肝窦', 0.26862600445747375),\n",
       " ('下甲', 0.26788684725761414),\n",
       " ('消瘦术后', 0.26783517003059387),\n",
       " ('隔略', 0.2678341269493103),\n",
       " ('期凸', 0.2667829394340515)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "rootPath = '/home/aid/Github/synonym_detection'\n",
    "\n",
    "model = gensim.models.Word2Vec.load(rootPath+'/word2vec/separated.model')\n",
    "model.wv.most_similar(positive=['未见'], topn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66de6ce-5549-4d98-be4a-53797536a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('发热', '高热')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e9eb66-f45f-4f37-935b-725c9b08dc3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 文本相似度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de5238-3d43-4561-89e3-a46fb1dd1f57",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 字面相似度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f75f835-541d-48a6-bbd6-3ea0995c2110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chars_sim_score(str1, str2):\n",
    "    \"\"\"字面相似度计算\"\"\"\n",
    "    def same_chars(str1, str2):\n",
    "        return set(str1) & set(str2)\n",
    "\n",
    "    dp = min(len(str1) / len(str2), len(str2) / len(str1))\n",
    "    alpha = 0.6\n",
    "    beta = 0.4\n",
    "    sames = same_chars(str1, str2)\n",
    "    def get_weighted(word, sames):\n",
    "        top = 0.0\n",
    "        bottom = 0.0\n",
    "        for idx, i in enumerate(word):\n",
    "            if i in sames:\n",
    "                top += (idx + 1)\n",
    "            bottom += (idx + 1)\n",
    "        return top / bottom\n",
    "\n",
    "    p1 = alpha * (len(sames) / len(str1) + len(sames) / len(str2)) / 2\n",
    "    p2 = beta * dp * (get_weighted(str1, sames) + get_weighted(str2, sames)) / 2\n",
    "    score = p1 + p2\n",
    "    return score, sames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da18fb37-cba8-4ca3-a9e3-7d8e5cc02afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_chars_sim_score('想你', '不想你')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b881f2c-3771-412d-8424-646131c01fcd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 句子计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc400cce-5b25-4646-9084-060a1c19da18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import numpy as np\n",
    "\n",
    "def encode(model, sentences):\n",
    "    all_embeddings = []\n",
    "    for sentence in sentences:\n",
    "        emb = []\n",
    "        count = 0\n",
    "        for word in jieba.cut(sentence):\n",
    "            # 调用词向量\n",
    "            if word in model.wv.key_to_index:\n",
    "                emb.append(model.wv.get_vector(word, norm=True))\n",
    "                count += 1\n",
    "            else:\n",
    "                if len(word) == 1:\n",
    "                    continue\n",
    "                \n",
    "        tensor_x = np.array(emb).sum(axis=0)  # 纵轴相加\n",
    "        if count > 0:\n",
    "            avg_tensor_x = np.divide(tensor_x, count)\n",
    "        else:\n",
    "            avg_tensor_x = 0.0\n",
    "        all_embeddings.append(avg_tensor_x)\n",
    "    all_embeddings = np.array(all_embeddings)\n",
    "    return all_embeddings\n",
    "\n",
    "\n",
    "def try_divide(x, y, val=0.0):\n",
    "    \"\"\"\n",
    "    try to divide two numbers\n",
    "    \"\"\"\n",
    "    if y != 0.0:\n",
    "        val = float(x) / y\n",
    "    return val\n",
    "\n",
    "\n",
    "def cosine_distance(v1, v2):\n",
    "    \"\"\"\n",
    "    余弦距离\n",
    "    return cos score\n",
    "    \"\"\"\n",
    "    up = float(np.sum(v1 * v2))\n",
    "    down = np.linalg.norm(v1) * np.linalg.norm(v2)\n",
    "    return try_divide(up, down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "884b6a5f-a127-482b-b723-3db90d801a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6186868791128292"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1 = encode(model, ['双侧大小脑半球灰白质界限清楚'])\n",
    "e2 = encode(model, ['两侧脑实质未见明显异常信号影'])\n",
    "cos_score = cosine_distance(e1, e2)\n",
    "cos_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5617ff-93f0-44d2-974b-960c9f300ee6",
   "metadata": {},
   "source": [
    "## 其它"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71540908-1133-44c7-b8d4-a36a2aae4547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无/v 明显/a 紫绀/n ，/x 非/h 癫痫/n 事件/n ，/x 癫痫/n 较/d 前无/i 明显降低/n ,/x  /x 不是/c ，/x 非/h ，/x 不可/v ，/x 未/d 见/v \n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "\n",
    "text = \"无明显紫绀，非癫痫事件，癫痫较前无明显降低, 不是，非，不可，未见\"\n",
    "text_cut = jieba.posseg.cut(text)\n",
    "text_wf = []\n",
    "for w in text_cut:\n",
    "    text_wf.append(w.word +'/'+ w.flag + ' ')\n",
    "print(\"\".join(text_wf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2535a9b-2f4e-4aed-bbc6-619eb0fa2271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "、，、。，，、。  、、、、、、、、、、。  ，、。，，、，，，，。，，，，。，、，，。、，、，、，、、，，。  ，，，，，，，、、。  ，，。  ，，、，。，。，，。  ，，，，。/，，>，，。  ，、，，，、，，，，。，，，，。，/，，。  。  ，，，、（），、，。  、，。、，、。，，，。  ，，，。，，，，，。。，，，，。  (--，)：：；；，。\", \"\": \"。\", \"\": \"        --     \n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"全身皮肤粘膜无黄染、紫绀，无皮疹、皮下出血。毛发分布正常，皮下无水肿，无肝掌、蜘蛛痣。  全身浅表淋巴结包括耳前、耳后、枕后、颈后、颈前、颌下、颏下、锁骨上、腘窝、滑车、腹股沟等淋巴结未触及肿大。  头颅大小正常，无畸形、压痛。双侧眼睑无水肿及下垂，无倒睫，结膜无充血、水肿，眼球运动自如，双侧巩膜无黄染，双侧瞳孔等大等圆，对光反射灵敏。双侧耳廓无畸形，无耳瘘，外耳道无异常分泌物，双侧乳突无压痛，双侧听力粗试无障碍。鼻外观无畸形，无鼻翼扇动、鼻塞及分泌物，鼻窦无压痛，双侧鼻唇沟对称。口唇无紫绀、苍白，口腔粘膜无溃疡、出血点，伸舌无偏斜、震颤，齿龈无肿胀、溢脓、出血，咽部粘膜无充血，双侧扁桃体无肿大。  颈部对称，无抵抗，颈动脉搏动正常，颈静脉无怒张，气管居中，肝颈静脉回流征阴性，甲状腺无肿大，无压痛、震颤、血管杂音。  胸廓无畸形，胸骨无压痛，乳房正常对称。  双侧呼吸运动对称，呼吸规整，肋间隙无增宽、变窄，双侧语颤正常对称。双肺叩诊清音，双肺下界移动度正常对称。双肺呼吸音清晰，未闻及干湿性啰音，无胸膜摩擦音。  心前区无隆起，心尖搏动位于左第五肋间锁骨中线内0.5cm，无抬举感，无震颤，心相对浊音界无扩大。心率80次/分，律齐，A2>P2，各瓣膜听诊区未闻及杂音，无心包摩擦音。  腹平坦，未见胃形、肠形，无腹壁静脉曲张，腹壁柔软，全腹无压痛、反跳痛，未触及包块，肝脏肋下未触及，脾脏肋下未触及，墨菲氏征阴性。叩诊呈鼓音，肝上界位于右锁骨中线第五肋间，肝区无叩击痛，移动性浊音阴性，双肾区无叩击痛。肠鸣音无亢进或减弱，4次/分，无气过水音，未闻及血管杂音。  肛门及外生殖器无异常。  脊柱生理弯度存在，无侧弯，四肢活动自如，无畸形、杵状指（趾），关节无红肿、变形，双下肢无浮肿。  四肢肌力、肌张力正常对称，腹壁反射存在。双侧肱二、三头肌腱反射正常对称，双侧膝反射、跟腱反射正常对称。双侧霍夫曼氏征阴性，双侧巴氏征阴性，克氏征阴性，布氏征阴性。  神清，精神反应一般，头部可见陈旧手术疤痕，愈合良好。眼睑无下垂，双侧眼结膜无充血水肿，双侧瞳孔等大等圆，对光反射灵敏，呼吸平顺，双肺未闻及罗音。腹软不张。四肢活动自如，双侧膝反射可引出，克氏征，布氏征，巴氏征均为阴性。  头颅MR(2016-06-14，我院)：癫痫术后复查：右枕部部分脑组织缺如；并右顶枕部硬膜下少许出血；右顶枕部头皮肿胀，请结合临床。\", \"家族史\": \"见第一次住院病历。\", \"诊断\": \"  1.难治性癫痫  2.抑郁综合征  樊轶斌  2016-08-22  第 页  \"\"\"\n",
    "text_cut = jieba.posseg.cut(text)\n",
    "\n",
    "seg_word_dict = {}\n",
    "for w in text_cut:\n",
    "    if w.flag in seg_word_dict.keys():\n",
    "        seg_word_dict[w.flag] += w.word\n",
    "    else:\n",
    "        key = w.flag\n",
    "        value = w.word\n",
    "        seg_word_dict[key] = value\n",
    "print(seg_word_dict['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdda6ffb-5001-435b-aa1b-3e72eef7486b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
