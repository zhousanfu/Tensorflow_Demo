{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\" #bert-large-uncased\n",
    "model_path = 'model/ivdr_text_classification'\n",
    "vocab_size = 10000  # 词汇表大小\n",
    "embedding_dim = 100  # 词向量维度\n",
    "hidden_size = 128 #128  # LSTM隐藏层大小\n",
    "max_sequence_length = 128\n",
    "batch_size = 20\n",
    "\n",
    "num_classes = 4\n",
    "epochs_classes = 10\n",
    "classification_learning_rate = 0.00001\n",
    "weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('data/ivdr_classification_referance.csv')\n",
    "df_2 = pd.read_csv('data/ivdr分类训练数据.csv', sep=',')\n",
    "df_1 = df_1[['device_type', 'device_name']]\n",
    "df_2 = df_2.dropna(subset=['product_name'])\n",
    "df_2 = df_2[['risk_class', 'product_name']]\n",
    "df_2.columns = ['device_type', 'device_name']\n",
    "\n",
    "class_map = {\n",
    "    'Class A': 0,\n",
    "    'Class B': 1,\n",
    "    'Class C': 2,\n",
    "    'Class D': 3\n",
    "}\n",
    "\n",
    "merged_df = pd.concat([df_1, df_2])\n",
    "merged_df.replace({'device_type': class_map}, inplace=True)\n",
    "\n",
    "print(merged_df['device_type'].value_counts())\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据和标签\n",
    "data = merged_df.to_dict(orient='list')\n",
    "sentences = data['device_name']\n",
    "labels = data['device_type']\n",
    "\n",
    "# 划分训练集和验证集\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(sentences, labels, test_size=0.2, random_state=42)\n",
    "train_data, eval_data, train_labels, eval_labels = train_test_split(train_data, train_labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 编码训练集和验证集的输入文本\n",
    "train_encodeds = tokenizer.batch_encode_plus(train_data, truncation=True, padding='max_length', max_length=max_sequence_length, return_tensors='tf')\n",
    "test_encodeds = tokenizer.batch_encode_plus(test_data, truncation=True, padding='max_length', max_length=max_sequence_length, return_tensors='tf')\n",
    "eval_encodeds = tokenizer.batch_encode_plus(eval_data, truncation=True, padding='max_length', max_length=max_sequence_length, return_tensors='tf')\n",
    "# input_ids = tf.convert_to_tensor(encodeds['input_ids'])\n",
    "# attention_mask = tf.convert_to_tensor(encodeds['attention_mask'])\n",
    "# labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "# 转换为TensorFlow Dataset格式\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices( \\\n",
    "    ({'input_ids': train_encodeds['input_ids'], 'attention_mask': train_encodeds['attention_mask']}, train_labels) \\\n",
    "    ).shuffle(num_classes).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices( \\\n",
    "    ({'input_ids': test_encodeds['input_ids'], 'attention_mask': test_encodeds['attention_mask']}, test_labels) \\\n",
    "    ).shuffle(num_classes).batch(batch_size)\n",
    "eval_dataset = tf.data.Dataset.from_tensor_slices( \\\n",
    "    ({'input_ids': eval_encodeds['input_ids'], 'attention_mask': eval_encodeds['attention_mask']}, eval_labels) \\\n",
    "    ).shuffle(num_classes).batch(batch_size)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义TFBertForSequenceClassification模型\n",
    "classes_model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=classification_learning_rate)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# 定义评估指标\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
    "eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('eval_accuracy')\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "eval_loss = tf.keras.metrics.Mean('eval_loss', dtype=tf.float32)\n",
    "\n",
    "@tf.function\n",
    "def train_step(inputs, labels):\n",
    "    predictions = None\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = classes_model(inputs, training=True)[0]\n",
    "        loss_value = loss(labels, outputs)\n",
    "        predictions = tf.argmax(outputs, axis=1)\n",
    "\n",
    "    gradients = tape.gradient(loss_value, classes_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, classes_model.trainable_variables))\n",
    "\n",
    "    train_accuracy(labels, outputs)\n",
    "    train_loss(loss_value)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "@tf.function\n",
    "def eval_step(inputs, labels):\n",
    "    outputs = classes_model(inputs, training=False)[0]\n",
    "    loss_value = loss(labels, outputs)\n",
    "\n",
    "    eval_accuracy(labels, outputs)\n",
    "    eval_loss(loss_value)\n",
    "\n",
    "    predictions = tf.argmax(outputs, axis=1)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "@tf.function\n",
    "def test_step(inputs, labels):\n",
    "    outputs = classes_model(inputs, training=False)[0]\n",
    "    loss_value = loss(labels, outputs)\n",
    "\n",
    "    test_accuracy(labels, outputs)\n",
    "    test_loss(loss_value)\n",
    "\n",
    "    predictions = tf.argmax(outputs, axis=1)\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "train_acc_scores = []\n",
    "eval_acc_scores = []\n",
    "for epoch in range(epochs_classes):\n",
    "    train_accuracy.reset_states()\n",
    "    eval_accuracy.reset_states()\n",
    "    train_loss.reset_states()\n",
    "    eval_loss.reset_states()\n",
    "    train_predictions = []\n",
    "    eval_predictions = []\n",
    "    train_f1 = 0\n",
    "    eval_f1 = 0\n",
    "\n",
    "    for batch_inputs, batch_labels in train_dataset:\n",
    "        predictions = train_step(batch_inputs, batch_labels)\n",
    "        train_predictions.extend(predictions)\n",
    "\n",
    "    for batch_inputs, batch_labels in eval_dataset:\n",
    "        predictions = eval_step(batch_inputs, batch_labels)\n",
    "        eval_predictions.extend(predictions)\n",
    "\n",
    "    train_f1 = f1_score(train_labels, train_predictions)\n",
    "    eval_f1 = f1_score(eval_labels, eval_predictions)\n",
    "    train_acc_scores.append(train_accuracy.result().numpy())\n",
    "    eval_acc_scores.append(eval_accuracy.result().numpy())\n",
    "    print('Epoch {}: 训练: Loss: {:.4f}, Accuracy: {:.4f}, F1: {:.4f}, 验证: Loss: {:.4f}, Accuracy: {:.4f}, F1: {:.4f},'.format(\n",
    "        epoch + 1, train_loss.result(), train_accuracy.result(), train_f1, eval_loss.result(), eval_accuracy.result(), eval_f1\n",
    "    ))\n",
    "\n",
    "plt.plot(range(epochs_classes), train_acc_scores, label='Train')\n",
    "plt.plot(range(epochs_classes), eval_acc_scores, label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_model.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_model = TFBertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "classes_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy.reset_states()\n",
    "test_loss.reset_states()\n",
    "test_predictions = []\n",
    "test_f1 = 0\n",
    "for batch_inputs, batch_labels in test_dataset:\n",
    "    predictions = test_step(batch_inputs, batch_labels)\n",
    "    test_predictions.extend(predictions)\n",
    "test_f1 = f1_score(test_labels, test_predictions, average='micro')\n",
    "\n",
    "print(test_loss.result().numpy(), test_accuracy.result().numpy(), test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = classes_model.predict(test_dataset)\n",
    "# probabilities = tf.nn.softmax(outputs.logits, axis=1)\n",
    "\n",
    "# for i in probabilities:\n",
    "#     predicted_label = tf.argmax([i], axis=1).numpy()[0]\n",
    "#     print(\"预测标签:\", predicted_label, i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('data/ivdr_classification_referance.csv')\n",
    "df_2 = pd.read_csv('data/ivdr分类训练数据.csv', sep=',')\n",
    "df_1 = df_1[['device_type', 'device_name']]\n",
    "df_2 = df_2.dropna(subset=['product_name'])\n",
    "df_2 = df_2[['risk_class', 'product_name']]\n",
    "df_2.columns = ['device_type', 'device_name']\n",
    "\n",
    "class_map = {\n",
    "    'Class A': 0,\n",
    "    'Class B': 1,\n",
    "    'Class C': 2,\n",
    "    'Class D': 3\n",
    "}\n",
    "\n",
    "merged_df = pd.concat([df_1, df_2])\n",
    "merged_df.replace({'device_type': class_map}, inplace=True)\n",
    "\n",
    "print(merged_df['device_type'].value_counts())\n",
    "data = merged_df.to_dict(orient='list')\n",
    "sentences = data['device_name']\n",
    "labels = data['device_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['Class A', 'Class B', 'Class C', 'Class D']\n",
    "text = \"Limusave MT-7501\"\n",
    "\n",
    "out_data = []\n",
    "for i in range(len(sentences)):\n",
    "    text = sentences[i]\n",
    "    input_ids = tokenizer.encode(text, add_special_tokens=True)\n",
    "    input_ids = tf.convert_to_tensor([input_ids])  # 转换为 TensorFlow 张量\n",
    "    outputs = classes_model.predict(input_ids)\n",
    "    probabilities = tf.nn.softmax(outputs.logits, axis=1)\n",
    "    predicted_index = np.argmax(probabilities, axis=1)\n",
    "    predicted_label = label_list[predicted_index[0]]\n",
    "    out_data.append({\n",
    "        'text': text,\n",
    "        'predict': predicted_label,\n",
    "        'label': labels[i],\n",
    "        'classA': probabilities[0].numpy()[0],\n",
    "        'classB': probabilities[0].numpy()[1],\n",
    "        'classC': probabilities[0].numpy()[2],\n",
    "        'classD': probabilities[0].numpy()[3]\n",
    "        })\n",
    "    \n",
    "df = pd.json_normalize(out_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_values(row):\n",
    "    if row['predict'] == row['label']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "class_map = {\n",
    "    'Class A': 0,\n",
    "    'Class B': 1,\n",
    "    'Class C': 2,\n",
    "    'Class D': 3\n",
    "}\n",
    "df.replace({'predict': class_map}, inplace=True)\n",
    "# df['label'] = df['label'].astype(str)\n",
    "df['result'] = df.apply(compare_values, axis=1)\n",
    "\n",
    "df.to_excel('data/ivdr_classification_out.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['result'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.9889543446244478 {1: 7351, 0: 470}\n",
      "0.41 0.9399053829433577 {1: 7351, 0: 470}\n",
      "0.42 0.9399053829433577 {1: 7350, 0: 463}\n",
      "0.43 0.9407397926532702 {1: 7350, 0: 463}\n",
      "0.44 0.9407397926532702 {1: 7350, 0: 461}\n",
      "0.45 0.9409806682883114 {1: 7350, 0: 460}\n",
      "0.46 0.941101152368758 {1: 7350, 0: 459}\n",
      "0.47 0.9412216673069536 {1: 7345, 0: 456}\n",
      "0.48 0.941545955646712 {1: 7345, 0: 452}\n",
      "0.49 0.9420289855072463 {1: 7345, 0: 449}\n",
      "0.5 0.9423915832691814 {1: 7338, 0: 443}\n",
      "0.51 0.9430664439018122 {1: 7332, 0: 439}\n",
      "0.52 0.9435079140393772 {1: 7326, 0: 428}\n",
      "0.53 0.9448026824864586 {1: 7319, 0: 420}\n",
      "0.54 0.9457294224059956 {1: 7311, 0: 417}\n",
      "0.55 0.9460403726708074 {1: 7303, 0: 407}\n",
      "0.56 0.9472114137483787 {1: 7297, 0: 403}\n",
      "0.57 0.9476623376623377 {1: 7289, 0: 393}\n",
      "0.58 0.9488414475397032 {1: 7279, 0: 384}\n",
      "0.59 0.9498890773848362 {1: 7275, 0: 374}\n",
      "0.6 0.9511047195711858 {1: 7271, 0: 373}\n",
      "0.61 0.9512035583464155 {1: 7269, 0: 364}\n",
      "0.62 0.9523123280492598 {1: 7261, 0: 359}\n",
      "0.63 0.9528871391076116 {1: 7241, 0: 348}\n",
      "0.64 0.9541441560152852 {1: 7235, 0: 337}\n",
      "0.65 0.9554939249867934 {1: 7221, 0: 326}\n",
      "0.66 0.956804028090632 {1: 7210, 0: 319}\n",
      "0.67 0.9576304954177182 {1: 7201, 0: 307}\n",
      "0.68 0.9591102823654768 {1: 7190, 0: 304}\n",
      "0.69 0.959434214037897 {1: 7178, 0: 298}\n",
      "0.7 0.9601391118245051 {1: 7168, 0: 294}\n",
      "0.71 0.9606003752345216 {1: 7148, 0: 288}\n",
      "0.72 0.9612694997310381 {1: 7135, 0: 281}\n",
      "0.73 0.962108953613808 {1: 7127, 0: 270}\n",
      "0.74 0.9634987156955522 {1: 7106, 0: 266}\n",
      "0.75 0.9639175257731959 {1: 7089, 0: 254}\n",
      "0.76 0.9654092332833991 {1: 7071, 0: 246}\n",
      "0.77 0.966379663796638 {1: 7057, 0: 241}\n",
      "0.78 0.9669772540422034 {1: 7036, 0: 230}\n",
      "0.79 0.9683457197908065 {1: 7016, 0: 227}\n",
      "0.8 0.9686593952781997 {1: 6986, 0: 225}\n",
      "0.81 0.9687976702260436 {1: 6942, 0: 215}\n",
      "0.82 0.9699594802291462 {1: 6907, 0: 206}\n",
      "0.83 0.9710389427808238 {1: 6882, 0: 202}\n",
      "0.84 0.971485036702428 {1: 6843, 0: 195}\n",
      "0.85 0.9722932651321398 {1: 6783, 0: 182}\n",
      "0.86 0.9738693467336683 {1: 6737, 0: 175}\n",
      "0.87 0.9746817129629629 {1: 6695, 0: 162}\n",
      "0.88 0.9763745078022459 {1: 6642, 0: 159}\n",
      "0.89 0.976621085134539 {1: 6575, 0: 151}\n",
      "0.9 0.9775498067201903 {1: 6484, 0: 144}\n",
      "0.91 0.9782739891369946 {1: 6382, 0: 133}\n",
      "0.92 0.9795855717574827 {1: 6239, 0: 119}\n",
      "0.93 0.9812834224598931 {1: 6007, 0: 100}\n",
      "0.94 0.9836253479613558 {1: 5682, 0: 82}\n",
      "0.95 0.9857737682165163 {1: 5372, 0: 60}\n",
      "0.96 0.9889543446244478 {1: 5151, 0: 47}\n",
      "0.97 0.9909580607926125 {1: 4881, 0: 44}\n",
      "0.98 0.9910659898477158 {1: 4764, 0: 40}\n"
     ]
    }
   ],
   "source": [
    "Accuracy = []\n",
    "Coverage = []\n",
    "threshold = []\n",
    "total_amount = len(df)\n",
    "\n",
    "for num in range(40, 99, +1):\n",
    "    num = num/100\n",
    "\n",
    "    filtered_df = df[(df['classA'] > num) | (df['classB'] > num) | (df['classC'] > num) | (df['classD'] > num)]\n",
    "    grouped = filtered_df['result'].value_counts().to_dict()\n",
    "    print(num, acc, grouped)\n",
    "    acc = grouped[1] / (grouped[0] + grouped[1])\n",
    "    cov = (grouped[0] + grouped[1]) / total_amount\n",
    "    Accuracy.append(acc)\n",
    "    Coverage.append(cov)\n",
    "    threshold.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts.charts import Line\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.globals import ThemeType\n",
    "\n",
    "\n",
    "x = [str(num) for num in threshold]\n",
    "y1 = [round(num, 2)*100 for num in Accuracy]\n",
    "y2 =  [round(num, 2)*100 for num in Coverage]\n",
    "line = (\n",
    "    Line(init_opts=opts.InitOpts(theme=ThemeType.LIGHT))\n",
    "    .set_global_opts(\n",
    "        title_opts=opts.TitleOpts(title=\"Two Lines\"),\n",
    "        xaxis_opts=opts.AxisOpts(name=\"阈值\"),\n",
    "        yaxis_opts=opts.AxisOpts(name=\"准确率\"),\n",
    "    )\n",
    "    .add_xaxis(xaxis_data=x)\n",
    "    .add_yaxis(series_name=\"Accuracy\", y_axis=y1)\n",
    "    .add_yaxis(series_name=\"Coverage\", y_axis=y2)\n",
    "    .render(\"落地效果预估.html\")\n",
    ")\n",
    "\n",
    "# line.render_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
