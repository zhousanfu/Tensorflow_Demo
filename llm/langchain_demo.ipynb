{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMURU65yCiBT"
   },
   "source": [
    "## Langchain\n",
    "\n",
    "LangChain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWFC32N9sIAp"
   },
   "outputs": [],
   "source": [
    "!pip install langchain faiss-cpu peft\n",
    "!pip install transformers sentence_transformers sentencepiece cpm_kernels llama-cpp-python\n",
    "!pip install google-search-results -i pypi.douban.com/simple --trusted-host pypi.douban.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVDV_5Ad2VIb"
   },
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSVWFuEV2VIb"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = LlamaCpp(model_path=\"models/chinese-alpaca-7b-int4/ggml-model-q4_0.bin\", callback_manager=callback_manager, verbose=True)\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's work this out in a step by step way to be sure we have the right answer.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "llm_chain.run(\"What NFL team won the Super Bowl in the year Justin Bieber was born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dS7ZeLoMv3dY"
   },
   "source": [
    "### google-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eWOG03owv-Hj"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "import os\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = '你的api key'\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"python_repl\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "agent.run(\"当前金价是多少一克？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7SE976V_CuP-"
   },
   "source": [
    "### prompt 提示\n",
    "填入内容来引导大模型输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FPt2QqzyCtsB"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    PromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "template = \"\"\"什么是{query},还有如何真正做到并细说实现步骤\"\"\"\n",
    "prompt_tem = PromptTemplate(input_variables=[\"query\"], template=template)\n",
    "prompt = prompt_tem.format(query='阶级跳跃')\n",
    "\n",
    "response, history = llm(prompt=prompt, history=[])\n",
    "print(prompt, '-->', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_m3-jfGB7qs"
   },
   "outputs": [],
   "source": [
    "system_template = \"你是一个把{input_language}翻译成{output_language}的助手\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "messages = chat_prompt.format_prompt(input_language=\"英语\", output_language=\"汉语\", text=\"I love programming.\")\n",
    "\n",
    "messages.to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_MqGD66Di6z"
   },
   "source": [
    "### Chains 链\n",
    "链接多个组件处理一个特定的下游任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LYEVjYq4DlrN"
   },
   "outputs": [],
   "source": [
    "from langchain.chains.base import Chain\n",
    "\n",
    "class DemoChain():\n",
    "    def __init__(self, llm, prompt, history) -> None:\n",
    "        self.llm = llm\n",
    "        self.prompt = prompt\n",
    "        self.history = history\n",
    "\n",
    "    def run(self, query, history, context=None) -> Any:\n",
    "        if context is not None:\n",
    "            prompt = self.prompt.format(query=query, context=context)\n",
    "        else:\n",
    "            prompt = self.prompt.format(query=query)\n",
    "\n",
    "        response, history = self.llm(prompt, history)\n",
    "        return response, history\n",
    "\n",
    "chain = DemoChain(llm=llm, prompt=prompt_tem, history=[])\n",
    "response, history = chain.run(query=\"阶级跳跃\", history=[])\n",
    "print(response, history)\n",
    "\n",
    "chain = DemoChain(llm=llm, prompt=prompt_tem, history=[])\n",
    "response, history = chain.run(query=\"阶级跳跃\", history=[])\n",
    "print(response, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMMCMn6g2VIf"
   },
   "source": [
    "### 文档加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyM3WGCe2VIf"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import JSONLoader                    #pip install jq\n",
    "from langchain.document_loaders import UnstructuredMarkdownLoader    #pip install unstructured\n",
    "from langchain.document_loaders import PyPDFLoader                   #pip install pypdf\n",
    "from langchain.document_loaders import NotebookLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# loader = CSVLoader(file_path='./example_data/mlb_teams_2012.csv')\n",
    "# loader = UnstructuredHTMLLoader(\"example_data/fake-content.html\")\n",
    "# loader = JSONLoader(file_path='./example_data/facebook_chat.json', jq_schema='.messages[].content')\n",
    "# loader = UnstructuredMarkdownLoader('../README.md')\n",
    "# loader = PyPDFLoader(\"example_data/layout-parser-paper.pdf\")\n",
    "# loader = NotebookLoader(\"example_data/notebook.ipynb\")\n",
    "\n",
    "# loader = DirectoryLoader('data/pdf', glob=\"*.pdf\", loader_cls=PyPDFLoader, show_progress=True, use_multithreading=True)\n",
    "loader = DirectoryLoader('data/pdf', glob=\"*.PDF\", loader_cls=PyPDFLoader, show_progress=True, use_multithreading=True)\n",
    "documents = loader.load()\n",
    "\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JV1QmpVX2VIj"
   },
   "outputs": [],
   "source": [
    "# 文本分割器\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language       #代码分割\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "# with open('data/ner/test.txt') as f:\n",
    "#     state_of_the_union = f.read()\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(separator = \"\\n\\n\", chunk_size = 1000,chunk_overlap  = 200,length_function = len)\n",
    "# texts = text_splitter.create_documents([state_of_the_union])\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter.from_language(language=Language.PYTHON, chunk_size=50, chunk_overlap=0)\n",
    "# texts = text_splitter.create_documents(documents)\n",
    "\n",
    "texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKx53ahfSmKT"
   },
   "source": [
    "### Embedding\n",
    "外部信息编码成一个高维向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSnl7sJ32VIj"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"shibing624/text2vec-base-chinese\")\n",
    "embeddings = LlamaCppEmbeddings(model_path=\"model/chinese-alpaca-7b-int4/ggml-model-q4_0.bin\")\n",
    "\n",
    "query_result = embeddings.embed_query(\"阶级跳跃\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CbumQw0t2VIk"
   },
   "outputs": [],
   "source": [
    "#SentenceTransformers 文本和图像嵌入，语义文本相似性、语义搜索和同义词挖掘\n",
    "import sentence_transformers #pip install -U sentence-transformers\n",
    "\n",
    "embeddings.client = sentence_transformers.SentenceTransformer(embeddings.model_name, device='mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2Q1rroi2VIk"
   },
   "outputs": [],
   "source": [
    "# 向量库与检索\n",
    "from langchain.vectorstores import Chroma, FAISS                            #pip install faiss-cpu\n",
    "\n",
    "db = Chroma.from_documents(split_docs, embeddings,persist_directory=\"./vectors/chroma\")\n",
    "db.persist()\n",
    "db = Chroma(persist_directory=\"./vectors/chroma\", embedding_function=embeddings)\n",
    "db = FAISS.from_documents(split_docs, embeddings)\n",
    "db.save_local(\"./vectors/faiss\")\n",
    "db = FAISS.load_local(\"./vectors/faiss\",embeddings=embeddings)\n",
    "\n",
    "vector_store = FAISS.load_local(vs_path, embeddings)\n",
    "related_docs_with_score = vector_store.similarity_search_with_score(query=\"阶级跳跃\", k=2)\n",
    "context = \"\"\n",
    "for pack in related_docs_with_score:\n",
    "    doc, socre = pack\n",
    "    content = doc.page_content\n",
    "    print(\"检索到的知识=%s, from=%s, socre=%.3f\"%(content, doc.metadata.get(\"from\"), socre))\n",
    "    context += content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQ_CFNbDyAZM"
   },
   "source": [
    "### 文档问答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwjDxF44V64p"
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=db.as_retriever())\n",
    "qa.run(\"2022年腾讯营收多少\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xY29JpOaPR4N"
   },
   "source": [
    "### agents代理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dz6rK_VxPTyJ"
   },
   "outputs": [],
   "source": [
    "# pip install wikipedia\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools,\n",
    "                         llm,\n",
    "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                         verbose=True)\n",
    "\n",
    "\n",
    "agent.run(\"奥巴马的生日是哪天? 到2023年他多少岁了?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfgmWXlx_Pws"
   },
   "source": [
    "# 实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUWP4xNR_Uuf"
   },
   "source": [
    "## 信息抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZxCyTLZF3ur"
   },
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from langchain.llms.base import LLM\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from langchain.chains import SimpleSequentialChain, SequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.base import Chain\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3qYNlSXr3wX"
   },
   "outputs": [],
   "source": [
    "class CustomLLM(LLM):\n",
    "    def __init__(self, model_name, quantization_bit=4):\n",
    "        print('----1', model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        print('----2', model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name, trust_remote_code=True).half().cuda().eval()\n",
    "        # self.model = self.model.quantize(quantization_bit)\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "    ) -> str:\n",
    "        response, history = self.model.chat(self.tokenizer, prompt)\n",
    "        return response, history\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXAD14HCGJY9"
   },
   "outputs": [],
   "source": [
    "llm = CustomLLM(model_name=\"THUDM/chatglm-6B-int4\")\n",
    "llm(\"This is a foobar thing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Otck1zjw_WXS"
   },
   "outputs": [],
   "source": [
    "text = \"阿尔茨海默病(Alzheimer's disease, AD),俗称老年痴呆症,是一种全身性神经退行性疾病，它是由大脑神经退行性变性引起的，\\\n",
    "主要表现为记忆力减退、思维能力减退、行为变化等。阿尔茨海默病的原因尚不十分清楚，但是研究表明，阿尔茨海默病可能与遗传因素、环境因素、\\\n",
    "营养不良、压力过大、不良生活习惯等有关。根据世界卫生组织的统计数据，全球有超过4700万人患有阿尔茨海默病，其中美国有超过600万人患有阿尔茨海默病，\\\n",
    "欧洲有超过1000万人患有阿尔茨海默病，亚洲有超过2500万人患有阿尔茨海默病，其中中国有超过1000万人患有阿尔茨海默病。阿尔茨海默病的发病率与年龄有关，\\\n",
    "随着年龄的增长而增加，65岁以上的人群为主要受害群体，占比高达80%，其中45-65岁的人群占比为15%，20-45岁的人群占比为5%。65岁以上的人群发病率约为10%，\\\n",
    "75岁以上的人群发病率约为20%，85岁以上的人群发病率约为30%。根据统计，男性患病率高于女性，男性患病比例为1.4：1，即男性患病率比女性高出40%。\\\n",
    "根据统计，阿尔茨海默病在不同的人种中分布情况也有所不同。白人患病率最高，占总患病率的70%，黑人患病率次之，占总患病率的20%，\\\n",
    "其他少数民族患病率最低，占总患病率的10%。阿尔茨海默病在不同的饮食习惯中分布情况也有所不同。维生素B12缺乏的人群患病率更高，\\\n",
    "而均衡膳食的人群患病率较低。阿尔茨海默病不仅会给患者带来记忆力减退、思维能力减退、行为变化等症状，还会给患者的家庭带来巨大的心理负担。\\\n",
    "因此，患者应尽快就医，及时进行治疗。治疗阿尔茨海默病的方法有药物治疗、行为治疗、认知行为治疗等，具体治疗方案要根据患者的具体情况而定。\"\n",
    "\n",
    "#创建模板\n",
    "fact_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"text_input\"],\n",
    "    template=\"从下面的本文中提取关键事实。尽量使用文本中的统计数据来说明事实:\\n\\n {text_input}\"\n",
    ")\n",
    "\n",
    "#定义chain\n",
    "fact_extraction_chain = LLMChain(llm=llm, prompt=fact_extraction_prompt)\n",
    "facts = fact_extraction_chain.run(text)\n",
    "print(facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwFPex-UEX31"
   },
   "outputs": [],
   "source": [
    "class ConcatenateChain(Chain):\n",
    "    chain_1: LLMChain\n",
    "    chain_2: LLMChain\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        # Union of the input keys of the two chains.\n",
    "        all_input_vars = set(self.chain_1.input_keys).union(set(self.chain_2.input_keys))\n",
    "        return list(all_input_vars)\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return ['concat_output']\n",
    "\n",
    "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
    "        output_1 = self.chain_1.run(inputs)\n",
    "        output_2 = self.chain_2.run(inputs)\n",
    "        return {'concat_output': output_1 + output_2}\n",
    "\n",
    "prompt_1 = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "chain_1 = LLMChain(llm=llm, prompt=prompt_1)\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good slogan for a company that makes {product}?\",\n",
    ")\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt_2)\n",
    "\n",
    "concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2)\n",
    "concat_output = concat_chain.run(\"colorful socks\")\n",
    "print(f\"Concatenated output:\\n{concat_output}\")\n",
    "\n",
    "\n",
    "concat_chain = ConcatenateChain(chain_1=chain_1, chain_2=chain_2)\n",
    "concat_output = concat_chain.run(\"colorful socks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6Ah9BnWAabw"
   },
   "outputs": [],
   "source": [
    "text = \"阿尔茨海默病(Alzheimer's disease, AD),俗称老年痴呆症,是一种全身性神经退行性疾病，它是由大脑神经退行性变性引起的，\\\n",
    "主要表现为记忆力减退、思维能力减退、行为变化等。阿尔茨海默病的原因尚不十分清楚，但是研究表明，阿尔茨海默病可能与遗传因素、环境因素、\\\n",
    "营养不良、压力过大、不良生活习惯等有关。根据世界卫生组织的统计数据，全球有超过4700万人患有阿尔茨海默病，其中美国有超过600万人患有阿尔茨海默病，\\\n",
    "欧洲有超过1000万人患有阿尔茨海默病，亚洲有超过2500万人患有阿尔茨海默病，其中中国有超过1000万人患有阿尔茨海默病。阿尔茨海默病的发病率与年龄有关，\\\n",
    "随着年龄的增长而增加，65岁以上的人群为主要受害群体，占比高达80%，其中45-65岁的人群占比为15%，20-45岁的人群占比为5%。65岁以上的人群发病率约为10%，\\\n",
    "75岁以上的人群发病率约为20%，85岁以上的人群发病率约为30%。根据统计，男性患病率高于女性，男性患病比例为1.4：1，即男性患病率比女性高出40%。\\\n",
    "根据统计，阿尔茨海默病在不同的人种中分布情况也有所不同。白人患病率最高，占总患病率的70%，黑人患病率次之，占总患病率的20%，\\\n",
    "其他少数民族患病率最低，占总患病率的10%。阿尔茨海默病在不同的饮食习惯中分布情况也有所不同。维生素B12缺乏的人群患病率更高，\\\n",
    "而均衡膳食的人群患病率较低。阿尔茨海默病不仅会给患者带来记忆力减退、思维能力减退、行为变化等症状，还会给患者的家庭带来巨大的心理负担。\\\n",
    "因此，患者应尽快就医，及时进行治疗。治疗阿尔茨海默病的方法有药物治疗、行为治疗、认知行为治疗等，具体治疗方案要根据患者的具体情况而定。\"\n",
    "\n",
    "\n",
    "#创建模板\n",
    "fact_extraction_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"从下面的本文中提取关键事实。尽量使用文本中的统计数据来说明事实:\\n\\n {query}\"\n",
    ")\n",
    "\n",
    "fact_extraction_chain = DemoChain(llm=llm, prompt=fact_extraction_prompt, history=[])\n",
    "response, history = fact_extraction_chain.run(query=text, history=[])\n",
    "print(response, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AG0-mJoOBbV6"
   },
   "outputs": [],
   "source": [
    "doctor_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"你是神经内科医生。根据以下阿尔茨海默病的事实统计列表，为您的病人写一个简短的预防阿尔茨海默病的建议。 不要遗漏关键信息：\\n\\n {query}\"\n",
    ")\n",
    "\n",
    "doctor_chain = DemoChain(llm=llm, prompt=doctor_prompt, history=history)\n",
    "response, history = doctor_chain.run(query=response, history=history)\n",
    "print(response, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "em9SQwT2B19B"
   },
   "outputs": [],
   "source": [
    "#定义SimpleSequentialChain\n",
    "full_chain = SimpleSequentialChain(chains=[fact_extraction_chain, doctor_chain], verbose=True)\n",
    "response, history = full_chain.run(text)\n",
    "print(response, history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VElacil74G1D"
   },
   "source": [
    "## 知识库智能问答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c04r-GBfGdkw"
   },
   "outputs": [],
   "source": [
    "!pip install langchain tiktoken pypdf faiss-cpu chromadb ctransformers sentence-transformers llama-cpp-python -q\n",
    "!pip install torch tabulate tqdm transformers accelerate sentencepiece chatglm-cpp pydantic-settings -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBgMtsZcIDAE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "EMBEDDING_DEVICE = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    !pip install ctransformers[cuda]\n",
    "EMBEDDING_DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYYRW6MUx60z"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.vectorstores import FAISS, Chroma\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import RetrievalQA, RetrievalQAWithSourcesChain\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fOtoZLhxv6d"
   },
   "source": [
    "**1 文档加载**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6MvBQvcXt1Ca"
   },
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('data/pdf/', glob=\"*.PDF\", loader_cls=PyPDFLoader, show_progress=True, use_multithreading=True)\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jV-mZi4oyC6H"
   },
   "source": [
    "**2 embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fgy9ubdHyFTC"
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"shibing624/text2vec-base-chinese\", model_kwargs={'device': EMBEDDING_DEVICE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkjxQh3G2VIr"
   },
   "outputs": [],
   "source": [
    "# !pip install llama-cpp-python\n",
    "# from langchain.embeddings import LlamaCppEmbeddings\n",
    "\n",
    "# embeddings = LlamaCppEmbeddings(model_path=\"models/Chinese-Llama-2-7b-ggml-q4.bin\")\n",
    "# embeddings.embed_query(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7O8QTLOyx7ws"
   },
   "source": [
    "**3 vector save or load**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvjUORcOyAIs"
   },
   "outputs": [],
   "source": [
    "vectordb = FAISS.from_documents(texts, embeddings)\n",
    "vectordb.save_local('vectordb/db_faiss')\n",
    "# FAISS.load_local('vectordb/db_faiss', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WByVvaLqi9g",
    "outputId": "45bfc6e0-5caf-464e-cf44-3a8ac67834bd"
   },
   "outputs": [],
   "source": [
    "vectordb = FAISS.load_local(\"vectordb/db_faiss\", embeddings)\n",
    "vectordb.similarity_search(\"非流动资产处置损益\", k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RK_wF1V-uCl_"
   },
   "source": [
    "**4 load llm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NFCONdgLphxE",
    "outputId": "be4edc91-4cfd-4d0e-cac1-17099b2cd5d6"
   },
   "outputs": [],
   "source": [
    "# !wget https://huggingface.co/TheBloke/Chinese-Alpaca-2-7B-GGUF/resolve/main/chinese-alpaca-2-7b.Q4_K_M.gguf\n",
    "!wget https://huggingface.co/Sanfor/chatglm-3-quantize/resolve/main/chatglm3-6b-q4_0-ggml.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0cwTQBeQKR2"
   },
   "source": [
    "Llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYQTsByz2VIt"
   },
   "outputs": [],
   "source": [
    "# from langchain.llms import LlamaCpp\n",
    "# from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# llm = LlamaCpp(\n",
    "#     model_path='chinese-alpaca-2-7b.Q6_K.gguf',\n",
    "#     n_ctx=2048,\n",
    "#     callbacks=[StreamingStdOutCallbackHandler()],\n",
    "#     verbose=False\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLmkFWDk2VIt"
   },
   "outputs": [],
   "source": [
    "llm = CTransformers(\n",
    "    model='chinese-alpaca-2-7b.Q4_K_M.gguf',\n",
    "    model_type='llama',\n",
    "    config={'max_new_tokens': 256, 'repetition_penalty': 1.1, 'temperature': 0.1, 'stream': True},\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    # gpu_layers=110 #110 for 7b, 130 for 13b\n",
    "    )\n",
    "llm(\"请列举5条文明乘车的建议\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSgzGc9lQNsj"
   },
   "source": [
    "ChatGLM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2d-ulb1ZYIz"
   },
   "outputs": [],
   "source": [
    "# import chatglm_cpp\n",
    "\n",
    "# pipeline = chatglm_cpp.Pipeline(\"chatglm3-6b-q4_0-ggml.bin\")\n",
    "# pipeline.chat([\"你好\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPVTDtlsIwrZ",
    "outputId": "91088312-c154-43b5-e21a-1b848dc1ba8c"
   },
   "outputs": [],
   "source": [
    "%%script bash\n",
    "CMAKE_ARGS=\"-DGGML_CUBLAS=ON\" pip install -U chatglm-cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pz0SCBQ5ghj"
   },
   "outputs": [],
   "source": [
    "%%script bash --bg\n",
    "MODEL=./chatglm3-6b-q4_0-ggml.bin uvicorn chatglm_cpp.langchain_api:app --host 127.0.0.1 --port 8000 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "WZSzwn7dUb1k",
    "outputId": "4b5e5794-2cc2-409f-96e8-492dab8297d7"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import ChatGLM\n",
    "llm = ChatGLM(endpoint_url=\"http://127.0.0.1:8000\")\n",
    "llm.predict(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KggBg1equF9v"
   },
   "source": [
    "**5 PromptTemplate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZuZYK0MGrtFd"
   },
   "outputs": [],
   "source": [
    "template =\"\"\"根据下面上下文（context）内容回答问题。\n",
    "如果你不知道答案，就回答不知道，不要试图编造答案。\n",
    "答案最多3句话，保持答案简洁。\n",
    "总是在答案结束时说“谢谢你的提问！”\n",
    "{context}\n",
    "问题：{question}\n",
    "答案：\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGu7T2DRyTUc"
   },
   "source": [
    "**6 检索问答**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrYoQ816J27E",
    "outputId": "36e022c5-066b-4357-fc76-be638ce7c317"
   },
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"shibing624/text2vec-base-chinese\", model_kwargs={'device': EMBEDDING_DEVICE})\n",
    "vectordb = FAISS.load_local(\"vectordb/db_faiss\", embeddings)\n",
    "\n",
    "# RetrievalQAWithSourcesChain\n",
    "qa_chat = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    retriever=vectordb.as_retriever(search_kwargs={'k':2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={'prompt': QA_CHAIN_PROMPT}\n",
    "    )\n",
    "\n",
    "qa_chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4H7K-sk7El0z",
    "outputId": "2834dd6a-0908-49c1-e3d4-9d14199c0843"
   },
   "outputs": [],
   "source": [
    "qa_chat(\"迈瑞医疗的研发副总经理是谁？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lo_D8X6wQCMP"
   },
   "source": [
    "## 翻译\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSeoi1IIMguE"
   },
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/Sanfor/chatglm-3-quantize/resolve/main/chatglm3-6b-q4_0-ggml.bin\n",
    "!pip install langchain pdfplumber PyPDF2 chatglm-cpp reportlab pdfminer.six uvloop>=0.14.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/Sanfor/chatglm-3-quantize/resolve/main/chatglm3-6b-q8_0-ggml.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TO-g9PYMnLW",
    "outputId": "92a31f6d-dc78-4c31-aebc-2dcc6d907d34"
   },
   "outputs": [],
   "source": [
    "%%script bash\n",
    "CMAKE_ARGS=\"-DGGML_CUBLAS=ON\" pip install -U chatglm-cpp #GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2_T02VoTMp8w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%script bash --bg\n",
    "MODEL=./chatglm3-6b-q4_0-ggml.bin uvicorn chatglm_cpp.langchain_api:app --host 127.0.0.1 --port 8000 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ikJEZBsxclHW"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import ChatGLM\n",
    "import pdfplumber\n",
    "from PyPDF2 import PdfWriter, PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "id": "sZkxtfcjMs3V",
    "outputId": "f804e44c-9f6b-4176-cf22-52b3ca30d3de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 95 ms, sys: 4.5 ms, total: 99.5 ms\n",
      "Wall time: 33.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The board of directors, the board of supervisors, and the directors, supervisors, and senior management personnel guarantee the authenticity, accuracy, and completeness of the quarterly reports, and they shall not contain any false statements, misleading statements, or significant omissions, and they shall bear individual and joint legal liabilities.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "template = \"你是一个翻译助手,请将下面的{source_language}翻译成{target_language}: \\n{text}\"\n",
    "translate_prompt = PromptTemplate(input_variables=[\"source_language\", \"target_language\", \"text\"], template=template)\n",
    "\n",
    "llm = ChatGLM(endpoint_url=\"http://127.0.0.1:8000\")\n",
    "# llm.predict(\"你好\")\n",
    "\n",
    "translated_chain = LLMChain(llm=llm, prompt=translate_prompt)\n",
    "translated_text = translated_chain.run({\n",
    "    \"text\": \"1.董事会、监事会及董事、监事、高级管理人员保证季度报告的真实、准确、完整，不存在虚假记载、误导性陈述或重大遗漏，并承担个别和连带的法律责任。\",\n",
    "    \"source_language\": \"中文\",\n",
    "    \"target_language\": \"英文\",\n",
    "    })\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uSd0O8u7QEry"
   },
   "outputs": [],
   "source": [
    "with pdfplumber.open(\"data/pdf/迈瑞医疗：2023年三季度报告.PDF\") as pdf:\n",
    "    # 获取PDF文件的页面数量\n",
    "    num_pages = len(pdf.pages)\n",
    "    # 获取页面对象\n",
    "    page = pdf.pages[0]\n",
    "    # 提取页面的文本内容\n",
    "    text = page.extract_text()\n",
    "    table = page.extract_table()\n",
    "    images = page.images\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pdfminer.layout.LTTextBoxHorizontal'> <LTTextBoxHorizontal(0) 57.075,754.078,533.170,766.978 '证券代码：300760                              证券简称：迈瑞医疗                        公告编号：2023-052 \\n'>\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from pdfminer.high_level import extract_pages\n",
    "from pdfminer.layout import LTTextBoxHorizontal\n",
    "from reportlab.pdfbase.ttfonts import TTFont\n",
    "from reportlab.pdfbase import pdfmetrics\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "\n",
    "def replace_text_in_pdf(input_pdf, output_pdf, replacements):\n",
    "    memory_file = BytesIO()\n",
    "    c = canvas.Canvas(memory_file)\n",
    "    pages = list(extract_pages(input_pdf))\n",
    "    for page_layout in pages:\n",
    "        # 获取页面大小\n",
    "        width, height = page_layout.width, page_layout.height\n",
    "        \n",
    "        # 绘制原始页面内容\n",
    "        for element in page_layout:\n",
    "            if isinstance(element, LTTextBoxHorizontal):\n",
    "                print(type(element), element)\n",
    "                for line in element._objs:\n",
    "                    print(type(line), dir(line), line)\n",
    "                    if hasattr(line, 'get_text'):\n",
    "                        font = element.fontname\n",
    "                        size = line.size\n",
    "                        text = line.get_text()\n",
    "                        x, y = line.bbox[0], height - line.bbox[3]\n",
    "                        c.setFont(font, size)\n",
    "                        c.drawString(x, y, text)\n",
    "        break\n",
    "\n",
    "#         # 在相同位置插入替换的文本\n",
    "#         for replacement in replacements.get(page_layout.pageid, []):\n",
    "#             font = replacement['fontname']\n",
    "#             size = replacement['size']\n",
    "#             text = replacement['text']\n",
    "#             x, y = replacement['x'], replacement['y']\n",
    "#             c.setFont(font, size)\n",
    "#             c.drawRightString(x, height - y, text)\n",
    "#         c.showPage()\n",
    "#     c.save()\n",
    "\n",
    "#     # 将生成的PDF写入文件\n",
    "#     with open(output_pdf, 'wb') as f:\n",
    "#         f.write(memory_file.getvalue())\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "input_pdf = 'data/pdf/迈瑞医疗：2023年三季度报告.PDF'\n",
    "output_pdf = 'data/pdf/迈瑞医疗：2023年三季度报告222.PDF'\n",
    "replacements = {\n",
    "    1: [{'x': 200, 'y': 300, 'fontname': 'Helvetica', 'size': 12, 'text': '替换后的文本'}]\n",
    "}\n",
    "\n",
    "replace_text_in_pdf(input_pdf, output_pdf, replacements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LTPage' object has no attribute 'to_xml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m input_pdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/pdf/迈瑞医疗：2023年三季度报告.PDF\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     42\u001b[0m output_pdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/pdf/迈瑞医疗：2023年三季度报告222.PDF\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mreplace_text_in_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_pdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_pdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplacements\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 34\u001b[0m, in \u001b[0;36mreplace_text_in_pdf\u001b[0;34m(input_pdf, output_pdf, replacements)\u001b[0m\n\u001b[1;32m     31\u001b[0m             element\u001b[38;5;241m.\u001b[39m_objs \u001b[38;5;241m=\u001b[39m [obj \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mget_text() \u001b[38;5;241m!=\u001b[39m old_text \u001b[38;5;28;01melse\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mreplace_with(new_text) \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m element\u001b[38;5;241m.\u001b[39m_objs]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 将页面添加到输出PDF文件\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m output\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_xml\u001b[49m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LTPage' object has no attribute 'to_xml'"
     ]
    }
   ],
   "source": [
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "\n",
    "def replace_text_in_pdf(input_pdf, output_pdf, replacements):\n",
    "    # 打开输入PDF文件\n",
    "    with open(input_pdf, 'rb') as file:\n",
    "        parser = PDFParser(file)\n",
    "        document = PDFDocument(parser)\n",
    "\n",
    "        # 创建PDF资源管理器和设备对象\n",
    "        rsrcmgr = PDFResourceManager()\n",
    "        laparams = LAParams()\n",
    "        device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "\n",
    "        # 打开输出PDF文件\n",
    "        with open(output_pdf, 'wb') as output:\n",
    "            # 遍历每一页\n",
    "            for page in PDFPage.create_pages(document):\n",
    "                interpreter.process_page(page)\n",
    "                layout = device.get_result()\n",
    "\n",
    "                # 遍历每个元素并替换文本\n",
    "                for element in layout:\n",
    "                    if isinstance(element, LTTextBoxHorizontal):\n",
    "                        for old_text, new_text in replacements.items():\n",
    "                            element._objs = [obj if obj.get_text() != old_text else obj.replace_with(new_text) for obj in element._objs]\n",
    "\n",
    "                # 将页面添加到输出PDF文件\n",
    "                output.write(device.get_result().to_xml())\n",
    "                \n",
    "replacements = {\n",
    "    '旧文本1': '新文本1',\n",
    "    '旧文本2': '新文本2',\n",
    "}\n",
    "\n",
    "input_pdf = 'data/pdf/迈瑞医疗：2023年三季度报告.PDF'\n",
    "output_pdf = 'data/pdf/迈瑞医疗：2023年三季度报告222.PDF'\n",
    "replace_text_in_pdf(input_pdf, output_pdf, replacements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from io import StringIO\n",
    "from reportlab.pdfgen import canvas\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    return_string = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(resource_manager, return_string, codec=codec, laparams=laparams)\n",
    "    interpreter = PDFPageInterpreter(resource_manager, device)\n",
    "\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        for page in PDFPage.get_pages(file):\n",
    "            interpreter.process_page(page)\n",
    "\n",
    "    text = return_string.getvalue()\n",
    "    device.close()\n",
    "    return_string.close()\n",
    "\n",
    "    return text\n",
    "\n",
    "def generate_pdf(text, output_path):\n",
    "    c = canvas.Canvas(output_path)\n",
    "    lines = text.split('\\n')\n",
    "    y = 750  # 设置初始的y坐标\n",
    "    for line in lines:\n",
    "        c.drawString(50, y, line)  # 在指定位置绘制文本\n",
    "        y -= 15  # 调整y坐标，使下一行文本向上移动\n",
    "    c.save()\n",
    "\n",
    "\n",
    "pdf_path = 'data/pdf/迈瑞医疗：2023年三季度报告.PDF'\n",
    "output_path = 'data/pdf/迈瑞医疗：2023年三季度报告2222.PDF'\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "generate_pdf(text, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "aUWP4xNR_Uuf"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
