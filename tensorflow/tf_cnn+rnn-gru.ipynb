{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    " \n",
    " \n",
    "#DL之CNN：基于CNN-RNN(GRU,2)算法(keras+tensorflow)实现不定长文本识别\n",
    " \n",
    " \n",
    "#Keras 的 CTC loss函数：位于 https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py文件中，内容如下：\n",
    " \n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import ctc_ops as ctc\n",
    " \n",
    "def ctc_batch_cost(y_true, y_pred, input_length, label_length):\n",
    "    \"\"\"Runs CTC loss algorithm on each batch element.\n",
    "    # Arguments\n",
    "        y_true: tensor `(samples, max_string_length)`\n",
    "            containing the truth labels.\n",
    "        y_pred: tensor `(samples, time_steps, num_categories)`\n",
    "            containing the prediction, or output of the softmax.\n",
    "        input_length: tensor `(samples, 1)` containing the sequence length for\n",
    "            each batch item in `y_pred`.\n",
    "        label_length: tensor `(samples, 1)` containing the sequence length for\n",
    "            each batch item in `y_true`.\n",
    "    # Returns\n",
    "        Tensor with shape (samples,1) containing the\n",
    "            CTC loss of each element.\n",
    "    \"\"\"\n",
    "    label_length = tf.to_int32(tf.squeeze(label_length))\n",
    "    input_length = tf.to_int32(tf.squeeze(input_length))\n",
    "    sparse_labels = tf.to_int32(ctc_label_dense_to_sparse(y_true, label_length))\n",
    " \n",
    "    y_pred = tf.log(tf.transpose(y_pred, perm=[1, 0, 2]) + 1e-8)\n",
    " \n",
    "    return tf.expand_dims(ctc.ctc_loss(inputs=y_pred, labels=sparse_labels, sequence_length=input_length), 1)\n",
    " \n",
    " \n",
    "# 不定长文本识别\n",
    "import os\n",
    "import itertools\n",
    "import re\n",
    "import datetime\n",
    "import cairocffi as cairo\n",
    "import editdistance\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import pylab\n",
    " \n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation, Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import EarlyStopping,Callback\n",
    " \n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    " \n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))\n",
    " \n",
    " \n",
    "OUTPUT_DIR = 'image_ocr'\n",
    "np.random.seed(55)\n",
    " \n",
    "# # 从 Keras 官方文件中 import 相关的函数\n",
    "# !wget https://raw.githubusercontent.com/fchollet/keras/master/examples/image_ocr.py\n",
    "from image_ocr import *\n",
    " \n",
    " \n",
    " \n",
    "#定义必要的参数：\n",
    "run_name = datetime.datetime.now().strftime('%Y:%m:%d:%H:%M:%S')\n",
    "start_epoch = 0\n",
    "stop_epoch  = 200\n",
    "img_w = 128\n",
    "img_h = 64\n",
    "words_per_epoch = 16000\n",
    "val_split = 0.2\n",
    "val_words = int(words_per_epoch * (val_split))\n",
    " \n",
    "# Network parameters\n",
    "conv_filters = 16\n",
    "kernel_size = (3, 3)\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "rnn_size = 512\n",
    "input_shape = (img_w, img_h, 1)\n",
    " \n",
    " \n",
    "# 使用这些函数以及对应参数构建生成器，生成不固定长度的验证码\n",
    "fdir = os.path.dirname(get_file('wordlists.tgz', origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n",
    "img_gen = TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n",
    "                                 bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),\n",
    "                                 minibatch_size=32, img_w=img_w, img_h=img_h,\n",
    "                                 downsample_factor=(pool_size ** 2), val_split=words_per_epoch - val_words )\n",
    " \n",
    "#构建CNN网络\n",
    "act = 'relu'\n",
    " \n",
    "input_data = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',  activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv1')(input_data)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "inner = Conv2D(conv_filters, kernel_size, padding='same',  activation=act, kernel_initializer='he_normal',\n",
    "                   name='conv2')(inner)\n",
    "inner = MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    " \n",
    "conv_to_rnn_dims = (img_w // (pool_size ** 2), (img_h // (pool_size ** 2)) * conv_filters)\n",
    "inner = Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    " \n",
    "#减少输入尺寸到RNN：cuts down input size going into RNN:  \n",
    "inner = Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    " \n",
    "#GRU模型：两层双向的算法\n",
    "# Two layers of bidirecitonal GRUs\n",
    "# GRU seems to work as well, if not better than LSTM:\n",
    "gru_1 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru1')(inner)\n",
    "gru_1b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru1_b')(inner)\n",
    "gru1_merged = add([gru_1, gru_1b])\n",
    "gru_2 = GRU(rnn_size, return_sequences=True, kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "gru_2b = GRU(rnn_size, return_sequences=True, go_backwards=True, kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    " \n",
    "#将RNN输出转换为字符激活：transforms RNN output to character activations\n",
    "inner = Dense(img_gen.get_output_size(), kernel_initializer='he_normal',\n",
    "                  name='dense2')(concatenate([gru_2, gru_2b]))\n",
    "y_pred = Activation('softmax', name='softmax')(inner)\n",
    " \n",
    "Model(inputs=input_data, outputs=y_pred).summary()\n",
    "labels = Input(name='the_labels', shape=[img_gen.absolute_max_string_len], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    " \n",
    " \n",
    "#Keras目前不支持带有额外参数的loss funcs，所以CTC loss是在lambda层中实现的\n",
    "# Keras doesn't currently support loss funcs with extra parameters, so CTC loss is implemented in a lambda layer\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    " \n",
    "#clipnorm似乎加快了收敛速度：clipnorm seems to speeds up convergence\n",
    "sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    " \n",
    "#计算损失发生在其他地方，所以使用一个哑函数来表示损失\n",
    "# the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "if start_epoch > 0:\n",
    "    weight_file = os.path.join(OUTPUT_DIR, os.path.join(run_name, 'weights%02d.h5' % (start_epoch - 1)))\n",
    "    model.load_weights(weight_file)\n",
    " \n",
    "#捕获softmax的输出，以便在可视化过程中解码输出\n",
    "# captures output of softmax so we can decode the output during visualization\n",
    "test_func = K.function([input_data], [y_pred])\n",
    " \n",
    "# 反馈函数，即运行固定次数后，执行反馈函数可保存模型，并且可视化当前训练的效果\n",
    "viz_cb = VizCallback(run_name, test_func, img_gen.next_val())\n",
    " \n",
    " \n",
    "# 执行训练：\n",
    "model.fit_generator(generator=img_gen.next_train(), steps_per_epoch=(words_per_epoch - val_words),\n",
    "                        epochs=stop_epoch, validation_data=img_gen.next_val(), validation_steps=val_words,\n",
    "                        callbacks=[EarlyStopping(patience=10), viz_cb, img_gen], initial_epoch=start_epoch)\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
