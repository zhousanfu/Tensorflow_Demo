{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhousanfu/machine-learning-demo/blob/master/LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbEDIhXr5QYP"
      },
      "outputs": [],
      "source": [
        "!pip install transformers sentence_transformers sentencepiece cpm_kernels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain faiss-cpu"
      ],
      "metadata": {
        "id": "g5uDtyPy8M7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results -i pypi.douban.com/simple --trusted-host pypi.douban.com"
      ],
      "metadata": {
        "id": "y1YCya_S-rOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chatglm"
      ],
      "metadata": {
        "id": "7uiRt-JmBtjz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbBCts3O3mX8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "from typing import Any, List, Mapping, Optional\n",
        "\n",
        "class chatGLM():\n",
        "    def __init__(self, model_name, quantization_bit=4) -> None:\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "        self.model = AutoModel.from_pretrained(model_name, trust_remote_code=True).half().cuda().eval()\n",
        "        self.model = self.model.quantize(quantization_bit)\n",
        "\n",
        "    def __call__(self, prompt, history) -> Any:\n",
        "        response, history = self.model.chat(self.tokenizer , prompt, history=history) # 这里演示未使用流式接口. stream_chat()\n",
        "        return response, history\n",
        "\n",
        "llm = chatGLM(model_name=\"THUDM/chatglm-6B-int4\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response, history = llm(prompt=\"你好\", history=[])\n",
        "print(\"response: %s\"%response)\n",
        "response, history = llm(prompt=\"我最近有点失眠怎么办?\", history=history)\n",
        "print(\"response: %s\"%response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8MrQIdOBhtc",
        "outputId": "924f72e6-67c1-4934-efe0-587ffc09214a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.THUDM.chatglm-6B-int4.02a065cf2797029c036a02cac30f1da1a9bc49a3.modeling_chatglm:The dtype of attention mask (torch.int64) is not bool\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "response: 你好👋！我是人工智能助手 ChatGLM-6B，很高兴见到你，欢迎问我任何问题。\n",
            "response: 失眠的话可以尝试下述方法进行改善：\n",
            "1. 睡前放松：在睡前放松身心，例如进行深呼吸、冥想、泡个热水澡或听柔和的音乐等。\n",
            "2. 建立规律的睡眠时间：尽量在同一时间入睡和起床，即使在周末和假期也要保持一定的规律。\n",
            "3. 避免刺激：在睡前避免过度刺激，例如看电子屏幕、使用电脑、使用手机等。\n",
            "4. 饮食调整：在睡前避免摄入咖啡因、酒精等刺激物质，可以适当增加一些易消化的食物，例如牛奶、面包等。\n",
            "5. 改善睡眠环境：保持卧室安静、黑暗、凉爽和舒适，如果有必要可以使用睡眠面罩、耳塞等工具。\n",
            "以上是一些改善失眠的方法，如果这些方法不能解决您的问题，可以咨询医生或专业人士的意见。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Langchain\n",
        "\n",
        "LangChain是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源"
      ],
      "metadata": {
        "id": "hMURU65yCiBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 官方llm使用OPENAI 接口\n",
        "# from langchain.llms import OpenAI\n",
        "# llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "# prompt = \"你好\"\n",
        "# response = llm(prompt)"
      ],
      "metadata": {
        "id": "RS4PLFqgSXtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### prompt\n",
        "填入内容来引导大模型输出"
      ],
      "metadata": {
        "id": "7SE976V_CuP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate\n",
        "\n",
        "\n",
        "\n",
        "template = \"\"\"什么是{query},还有如何真正做到并细说实现步骤\"\"\"\n",
        "prompt_tem = PromptTemplate(input_variables=[\"query\"], template=template)\n",
        "prompt = prompt_tem.format(query='阶级跳跃')\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FPt2QqzyCtsB",
        "outputId": "15cf7b26-7731-41e8-b2a3-f97097ddedc5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'什么是阶级跳跃,还有如何真正做到并细说实现步骤'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chains\n",
        "链接多个组件处理一个特定的下游任务"
      ],
      "metadata": {
        "id": "4_MqGD66Di6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.chains import LLMChain\n",
        "# chain = LLMChain(llm=openAI(), prompt=promptTem)\n",
        "# print(chain.run(\"你好\"))\n",
        "\n",
        "from langchain.chains.base import Chain\n",
        "\n",
        "\n",
        "\n",
        "class DemoChain():\n",
        "    def __init__(self, llm, prompt, history) -> None:\n",
        "        self.llm = llm\n",
        "        self.prompt = prompt\n",
        "        self.history = history\n",
        "\n",
        "    def run(self, query, history, context=None) -> Any:\n",
        "        if context is not None:\n",
        "            prompt = self.prompt.format(query=query, context=context)\n",
        "        else:\n",
        "            prompt = self.prompt.format(query=query)\n",
        "\n",
        "        response, history = self.llm(prompt, history)\n",
        "        return response, history\n",
        "\n",
        "chain = DemoChain(llm=llm, prompt=prompt_tem, history=[])\n",
        "response, history = chain.run(query=\"阶级跳跃\", history=[])\n",
        "print(response, history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYEVjYq4DlrN",
        "outputId": "f2e92911-c32b-4879-ed7a-25441050d209"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "阶级跳跃是指在一个游戏中，玩家通过一些技巧和策略，从一个普通的玩家直接跃变为高级玩家，例如一个初级玩家到高级玩家的阶级跨越。\n",
            "\n",
            "阶级跳跃通常需要玩家在初期积累大量的经验值和游戏币，然后使用这些积累来购买游戏中的高级物品和技能，或者在游戏中与其他玩家竞争，通过击败对手来获得更多的游戏币和经验值。\n",
            "\n",
            "实现阶级跳跃的详细步骤如下：\n",
            "\n",
            "1. 玩家需要在游戏中积累大量的经验值和游戏币。可以通过完成游戏中的任务、打败对手、获得奖励等方式来积累这些经验值和游戏币。\n",
            "\n",
            "2. 玩家需要学会一些高级物品和技能。这些物品和技能可以帮助玩家在游戏中获得更多的优势，例如更高的生命值、更高的攻击力、更多的技能等等。玩家需要在游戏中寻找这些物品和技能的踪迹，并学会使用它们。\n",
            "\n",
            "3. 玩家需要在游戏中与其他玩家竞争。与其他玩家竞争可以让玩家获得更多的游戏币和经验值，并提高自己的游戏水平。玩家需要找到一些强大的对手来竞争，并制定一些有效的策略来击败他们。\n",
            "\n",
            "4. 玩家需要在游戏中不断挑战自己。挑战自己可以让玩家不断提高自己的游戏水平，并在游戏中获得更多的优势。玩家需要在游戏中挑战一些难度较高的任务和对手，并不断提高自己的游戏水平。\n",
            "\n",
            "5. 玩家需要在游戏中与其他玩家合作。与其他玩家合作可以让玩家在游戏中获得更多的优势，并与其他玩家一起完成任务和挑战。玩家需要在游戏中寻找一些强大的队友来合作，并制定一些有效的策略来击败他们。\n",
            "\n",
            "以上是实现阶级跳跃的详细步骤，玩家需要在游戏中不断积累大量的经验值和游戏币，学会一些高级物品和技能，与其他玩家竞争，并不断提高自己的游戏水平，才能在游戏中实现阶级跳跃。 [('什么是阶级跳跃,还有如何真正做到并细说实现步骤', '阶级跳跃是指在一个游戏中，玩家通过一些技巧和策略，从一个普通的玩家直接跃变为高级玩家，例如一个初级玩家到高级玩家的阶级跨越。\\n\\n阶级跳跃通常需要玩家在初期积累大量的经验值和游戏币，然后使用这些积累来购买游戏中的高级物品和技能，或者在游戏中与其他玩家竞争，通过击败对手来获得更多的游戏币和经验值。\\n\\n实现阶级跳跃的详细步骤如下：\\n\\n1. 玩家需要在游戏中积累大量的经验值和游戏币。可以通过完成游戏中的任务、打败对手、获得奖励等方式来积累这些经验值和游戏币。\\n\\n2. 玩家需要学会一些高级物品和技能。这些物品和技能可以帮助玩家在游戏中获得更多的优势，例如更高的生命值、更高的攻击力、更多的技能等等。玩家需要在游戏中寻找这些物品和技能的踪迹，并学会使用它们。\\n\\n3. 玩家需要在游戏中与其他玩家竞争。与其他玩家竞争可以让玩家获得更多的游戏币和经验值，并提高自己的游戏水平。玩家需要找到一些强大的对手来竞争，并制定一些有效的策略来击败他们。\\n\\n4. 玩家需要在游戏中不断挑战自己。挑战自己可以让玩家不断提高自己的游戏水平，并在游戏中获得更多的优势。玩家需要在游戏中挑战一些难度较高的任务和对手，并不断提高自己的游戏水平。\\n\\n5. 玩家需要在游戏中与其他玩家合作。与其他玩家合作可以让玩家在游戏中获得更多的优势，并与其他玩家一起完成任务和挑战。玩家需要在游戏中寻找一些强大的队友来合作，并制定一些有效的策略来击败他们。\\n\\n以上是实现阶级跳跃的详细步骤，玩家需要在游戏中不断积累大量的经验值和游戏币，学会一些高级物品和技能，与其他玩家竞争，并不断提高自己的游戏水平，才能在游戏中实现阶级跳跃。')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding\n",
        "外部信息编码成一个高维向量"
      ],
      "metadata": {
        "id": "dKx53ahfSmKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #官方示例代码，用的OpenAI的ada的文本Embedding模型\n",
        "# #1） Embeding model\n",
        "# from langchain.embeddings import OpenAIEmbeddings\n",
        "# embeddings = OpenAIEmbeddings(model_name=\"ada\")\n",
        "# query_result = embeddings.embed_query(\"你好\")\n",
        "\n",
        "# #2) 文本切割\n",
        "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     chunk_size=100, chunk_overlap=0\n",
        "# )\n",
        "# texts = \"\"\"阶级跳跃是指一个人或一个组织通过提高自己的技能、知识和领导能力，从一个阶级跨越到另一个阶级的过程。要实现阶级跳跃，以下是一些建议：\\n\\n1. 学习新技能：学习新技能可以让人具备新的知识和技能，从而增加自己的竞争力。可以选择学习与目前工作相关的新技能，或者学习与未来工作相关的新技能。\\n\\n2. 提高知识水平：不断学习新知识可以增加自己的知识储备，从而提高自己的竞争力。可以通过阅读书籍、参加培训、参与线上课程等方式来提高自己的知识水平。\\n\\n3. 建立良好的人际关系：建立良好的人际关系可以让人更容易得到新机会，同时也可以获得更多的支持和帮助。可以通过参加社交活动、建立人脉、参加社区组织等方式来建立良好的人际关系。\\n\\n4. 提高自己的领导能力：领导能力可以让人更好地管理自己的时间和资源，从而更好地完成工作。可以通过参加领导力课程、参加团队建设活动、自我反思等方式来提高自己的领导能力。\\n\\n5. 建立自己的品牌：建立自己的品牌可以让人更容易被人记住，从而更容易得到新机会。可以通过写博客、发布视频、制作网站等方式来建立自己的品牌。\\n\\n阶级跳跃需要长期的努力和不断学习，需要对自己的能力和目标有清晰的认识，并制定明确的计划和目标。\"\"\"\n",
        "# texts = text_splitter.create_documents([texts])\n",
        "# print(texts[0].page_content)\n",
        "\n",
        "# # 3)入库检索，官方使用的Pinecone,他提供一个后台管理界面 | 用户需求太大，不好用了已经，一直加载中....\n",
        "# import pinecone\n",
        "# from langchain.vectorstores import Pinecone\n",
        "# pinecone.init(api_key=os.getenv(\"\"), enviroment=os.getenv(\"\"))\n",
        "\n",
        "# index_name = \"demo\"\n",
        "# search = Pinecone.from_documents(texts=texts, embeddings, index_name=index_name)\n",
        "# query = \"What is magical about an autoencoder?\"\n",
        "# result = search.similarity_search(query)\n",
        "\n",
        "### 这里使用chatGLM\n",
        "# 1） Embedding model:  text2vec-large-chinese"
      ],
      "metadata": {
        "id": "odYd5qgFSnIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "\n",
        "class TextSpliter(CharacterTextSplitter):\n",
        "    def __init__(self, separator: str = \"\\n\\n\", **kwargs: Any):\n",
        "        super().__init__(separator, **kwargs)\n",
        "\n",
        "    def split_text(self, text: str) -> List[str]:\n",
        "        texts = text.split(\"\\n\")\n",
        "        texts = [Document(page_content=text, metadata={\"from\": \"filename or book.txt\"}) for text in texts]\n",
        "        return texts\n",
        "\n",
        "texts = response\n",
        "\n",
        "text_splitter = TextSpliter()\n",
        "texts = text_splitter.split_text(texts)\n",
        "texts1 = [text.page_content for text in texts]\n",
        "\n",
        "texts1"
      ],
      "metadata": {
        "id": "KD-lRdx-Ynxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"GanymedeNil/text2vec-large-chinese\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs={'device': \"cuda\"})\n",
        "query_result = embeddings.embed_query(\"阶级跳跃\")\n",
        "\n",
        "np.array(query_result).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLkGJuZcbPUx",
        "outputId": "55517926-9523-40b5-8e16-d170c4d61051"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1024,)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vs_path = \"text_to_emb\"\n",
        "\n",
        "docs = embeddings.embed_documents(texts1)\n",
        "\n",
        "vector_store = FAISS.from_documents(texts, embeddings)\n",
        "vector_store.save_local(vs_path)\n",
        "\n",
        "vector_store = FAISS.load_local(vs_path, embeddings)\n",
        "related_docs_with_score = vector_store.similarity_search_with_score(query=\"阶级跳跃\", k=2)"
      ],
      "metadata": {
        "id": "x7vw5wD6bOLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5 基于查询到的知识做prompt\n",
        "context = \"\"\n",
        "for pack in related_docs_with_score:\n",
        "    doc, socre = pack\n",
        "    content = doc.page_content\n",
        "    print(\"检索到的知识=%s, from=%s, socre=%.3f\"%(content, doc.metadata.get(\"from\"), socre))\n",
        "    context += content\n",
        "\n",
        "# 重新配置一个基于上下文的模板在来调下语言模型\n",
        "template = \"已知{context}, 请给我解释一下{query}的意思?\"\n",
        "promptTem = PromptTemplate(input_variables=[\"context\", \"query\"], template=template)\n",
        "chain = DemoChain(llm=llm, prompt=promptTem)\n",
        "print(\"-\"*80)\n",
        "print(chain.run(query=\"天道酬勤\", context=context))\n",
        "print(\"-\"*80)"
      ],
      "metadata": {
        "id": "J8-n7QC2dS8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### llm重写\n",
        "\n",
        "TfboyLLM继承了langchain.llms.base的LLM类。需要实现它的两个方法：\n",
        "\n",
        "*   _call: 主要的处理方法，对传来的prompt问题分析，给他一个答案。return\n",
        "\n",
        "*   _identifying_params: 说明LLM类中的参数和数值。本例中没有类的成员变量。\n",
        "\n",
        "\n",
        "其实关键要看_call中实现的逻辑：\n",
        "收到prompt先打印出来。\n",
        "对问题正则匹配，规则为：[数字]+[运算符]+[数字]。匹配到，返回计算结果。匹配不到继续执行。\n",
        "判断有没有[?]。如果有，则对文本中字符进行替换，规则为：我->你, 你->我, 吗->\"\", ?->!。\n",
        "如果都不符合，就返回：“很抱歉，请换一种问法。比如：1+1等于几”。"
      ],
      "metadata": {
        "id": "6dkGGNwJ77Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Any, List, Mapping, Optional\n",
        "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain.llms.base import LLM\n",
        "import re\n",
        "\n",
        "class TfboyLLM(LLM):\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        return \"custom\"\n",
        "\n",
        "    def _call(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "    ) -> str:\n",
        "        print(\"问题:\",prompt)\n",
        "        pattern = re.compile(r'^.*(\\d+[*/+-]\\d+).*$')\n",
        "        match = pattern.search(prompt)\n",
        "        if match:\n",
        "            result = eval(match.group(1))\n",
        "        elif \"？\" in prompt:\n",
        "            rep_args = {\"我\":\"你\", \"你\":\"我\", \"吗\":\"\", \"？\":\"！\"}\n",
        "            result = [(rep_args[c] if c in rep_args else c) for c in list(prompt)]\n",
        "            result = ''.join(result)\n",
        "        else:\n",
        "            result = \"很抱歉，请换一种问法。比如：1+1等于几\"\n",
        "        return result\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Mapping[str, Any]:\n",
        "        return {}\n",
        "\n"
      ],
      "metadata": {
        "id": "4GQgTpN_7xyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = TfboyLLM()\n",
        "print(\"答案:\",llm(\"我能问你问题吗？\"))"
      ],
      "metadata": {
        "id": "6-ra4sWw8AnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9YP_o9wKSlNl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXVHgVjC10TvuwtkgnKE9b",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}